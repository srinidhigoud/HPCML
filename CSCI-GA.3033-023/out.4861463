Num Workers = 1

0 2.8290393352508545
Train Epoch: 1 [0/20000 (0%)]	Loss: 2.829039
1 2.8060214519500732
2 2.7629973888397217
3 2.693298101425171
4 2.6694064140319824
5 2.571737766265869
6 2.4435787200927734
7 2.383152723312378
8 2.2160863876342773
9 2.1577200889587402
10 1.9437987804412842
11 1.8767436742782593
12 1.7266719341278076
13 2.0080957412719727
14 1.8833520412445068
15 1.9556798934936523
16 1.8177986145019531
17 1.9127402305603027
18 1.7749210596084595
19 1.840285062789917
20 2.0030007362365723
21 1.8545928001403809
22 1.5197558403015137
23 1.780937671661377
24 1.6539002656936646
25 1.7829965353012085
26 1.8648076057434082
27 1.8329278230667114
28 1.5020310878753662
29 1.6889632940292358
30 1.6741061210632324
31 1.7439243793487549
32 1.6375197172164917
33 1.6369378566741943
34 1.6437673568725586
35 1.7501071691513062
36 1.5569405555725098
37 1.6637638807296753
38 1.5709691047668457
39 1.5887728929519653
40 1.5792268514633179
41 1.6114344596862793
42 1.639899730682373
43 1.540000319480896
44 1.4428205490112305
45 1.4737827777862549
46 1.7369827032089233
47 1.6305482387542725
48 1.6959720849990845
49 1.6131761074066162
50 1.5286517143249512
51 1.546218991279602
52 1.5843843221664429
53 1.516747236251831
54 1.3139090538024902
55 1.556215763092041
56 1.7605829238891602
57 1.582267165184021
58 1.481665015220642
59 1.6035263538360596
60 1.6657817363739014
61 1.6329426765441895
62 1.5672175884246826
63 1.5345083475112915
64 1.60272216796875
65 1.5785784721374512
66 1.4611091613769531
67 1.5422494411468506
68 1.5116363763809204
69 1.5527238845825195
70 1.4243972301483154
71 1.6189982891082764
72 1.448641300201416
73 1.4276999235153198
74 1.3877137899398804
75 1.4110591411590576
76 1.4062018394470215
77 1.3354359865188599
78 1.4939322471618652
79 1.5309981107711792
80 1.3737761974334717
81 1.4576283693313599
82 1.5447393655776978
83 1.489674687385559
84 1.261678695678711
85 1.5163297653198242
86 1.637821912765503
87 1.473139762878418
88 1.3398877382278442
89 1.4435049295425415
90 1.54972243309021
91 1.630863070487976
92 1.607609510421753
93 1.4731999635696411
94 1.4657034873962402
95 1.3424484729766846
96 1.4111824035644531
97 1.6452571153640747
98 1.60335111618042
99 1.4184997081756592
100 1.3764384984970093
Train Epoch: 1 [10000/20000 (50%)]	Loss: 1.376438
101 1.5298025608062744
102 1.4030959606170654
103 1.3301310539245605
104 1.5026293992996216
105 1.5864299535751343
106 1.429542064666748
107 1.4773750305175781
108 1.4035145044326782
109 1.576148509979248
110 1.4790735244750977
111 1.3770767450332642
112 1.561618685722351
113 1.4961073398590088
114 1.2327663898468018
115 1.425031304359436
116 1.3657538890838623
117 1.4344849586486816
118 1.2797482013702393
119 1.2829864025115967
120 1.4998234510421753
121 1.4419697523117065
122 1.367588996887207
123 1.5157501697540283
124 1.2679250240325928
125 1.3545732498168945
126 1.341853141784668
127 1.4502352476119995
128 1.1949056386947632
129 1.4194107055664062
130 1.282023310661316
131 1.3361457586288452
132 1.2833540439605713
133 1.3047518730163574
134 1.3402154445648193
135 1.227055549621582
136 1.258254885673523
137 1.1572097539901733
138 1.4244269132614136
139 1.1382349729537964
140 1.342617154121399
141 1.3814141750335693
142 1.4399343729019165
143 1.3312524557113647
144 1.3099044561386108
145 1.3327621221542358
146 1.3444464206695557
147 1.3171629905700684
148 1.4438809156417847
149 1.2141309976577759
150 1.2081555128097534
151 1.3495348691940308
152 1.3338922262191772
153 1.26200532913208
154 1.3590376377105713
155 1.3972057104110718
156 1.421329379081726
157 1.2068588733673096
158 1.4125953912734985
159 1.2181328535079956
160 1.3546217679977417
161 1.1607400178909302
162 1.1291124820709229
163 1.1466714143753052
164 1.247961401939392
165 1.194847822189331
166 1.1300089359283447
167 1.2669142484664917
168 1.214073896408081
169 1.2050297260284424
170 1.3455578088760376
171 1.20966374874115
172 1.2470364570617676
173 1.1759233474731445
174 1.1476984024047852
175 1.1356415748596191
176 1.3130578994750977
177 1.4372004270553589
178 1.3589770793914795
179 1.3476808071136475
180 1.2389755249023438
181 1.1980540752410889
182 1.2367169857025146
183 1.3366780281066895
184 1.2442435026168823
185 1.1918619871139526
186 1.1325207948684692
187 1.2249531745910645
188 1.2494853734970093
189 1.3126039505004883
190 1.2706553936004639
191 1.281863808631897
192 1.3909045457839966
193 1.370180606842041
194 1.30983304977417
195 1.326897144317627
196 1.084334135055542
197 1.274766206741333
198 1.2100909948349
199 1.3527822494506836
.............
178.30978270992637 47.41592136211693 221.94087808579206
.............
./lab1.pytorch:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  output = F.log_softmax(self.linear3(z))
0 1.3478392362594604
Train Epoch: 2 [0/20000 (0%)]	Loss: 1.347839
1 1.415611982345581
2 1.3437530994415283
3 1.2581071853637695
4 1.2426847219467163
5 1.4695781469345093
6 1.10036301612854
7 1.3442209959030151
8 1.1879360675811768
9 1.3585233688354492
10 1.0830674171447754
11 1.2661060094833374
12 1.1756078004837036
13 1.1991722583770752
14 1.2129192352294922
15 1.2786961793899536
16 1.2727117538452148
17 1.2668322324752808
18 1.346876621246338
19 1.1957573890686035
20 1.364600658416748
21 1.281211256980896
22 1.1874366998672485
23 1.3625096082687378
24 1.310359001159668
25 1.1654945611953735
26 1.3380422592163086
27 1.2928762435913086
28 1.1662958860397339
29 1.144038438796997
30 1.1657416820526123
31 1.253056287765503
32 1.211731195449829
33 1.2567243576049805
34 1.1873220205307007
35 1.3193565607070923
36 1.1430561542510986
37 1.173338532447815
38 1.1409313678741455
39 1.3120028972625732
40 1.0860655307769775
41 1.2775956392288208
42 1.3932576179504395
43 1.0948057174682617
44 1.0910253524780273
45 1.208357334136963
46 1.3337286710739136
47 1.2035564184188843
48 1.4432491064071655
49 1.2862533330917358
50 1.2985496520996094
51 1.203748345375061
52 1.2688655853271484
53 1.1911301612854004
54 1.0223851203918457
55 1.09534752368927
56 1.3122000694274902
57 1.186108946800232
58 1.2508535385131836
59 1.278220295906067
60 1.2925752401351929
61 1.1953343152999878
62 1.3137168884277344
63 1.1931464672088623
64 1.1795283555984497
65 1.1846462488174438
66 1.1594346761703491
67 1.4156068563461304
68 1.126409888267517
69 1.26795494556427
70 1.2370318174362183
71 1.4410334825515747
72 1.2140514850616455
73 1.1262656450271606
74 1.233096718788147
75 1.259516716003418
76 1.200353741645813
77 1.0328800678253174
78 1.2587969303131104
79 1.284471035003662
80 1.3064030408859253
81 1.2484298944473267
82 1.2643622159957886
83 1.2518820762634277
84 0.9833821654319763
85 1.2765661478042603
86 1.4049910306930542
87 1.2027661800384521
88 1.0287060737609863
89 1.2146087884902954
90 1.3400441408157349
91 1.4265475273132324
92 1.352737307548523
93 1.2418636083602905
94 1.300865888595581
95 1.1158668994903564
96 1.1676490306854248
97 1.3876179456710815
98 1.2096455097198486
99 1.2441271543502808
100 1.1247888803482056
Train Epoch: 2 [10000/20000 (50%)]	Loss: 1.124789
101 1.324042558670044
102 1.0880773067474365
103 1.1060010194778442
104 1.2632794380187988
105 1.2392789125442505
106 1.1816685199737549
107 1.2396347522735596
108 1.125055193901062
109 1.3513718843460083
110 1.2600141763687134
111 1.1630686521530151
112 1.3334263563156128
113 1.2409571409225464
114 1.120896816253662
115 1.2937496900558472
116 1.2141622304916382
117 1.230536699295044
118 1.1944630146026611
119 1.1102980375289917
120 1.2998920679092407
121 1.296266794204712
122 1.2360085248947144
123 1.3795892000198364
124 1.1420557498931885
125 1.213179111480713
126 1.2248011827468872
127 1.312199592590332
128 1.0071625709533691
129 1.3095614910125732
130 1.120558738708496
131 1.1876049041748047
132 1.1511015892028809
133 1.1183418035507202
134 1.1042879819869995
135 1.0429502725601196
136 1.1633458137512207
137 1.002609372138977
138 1.3096734285354614
139 1.0326526165008545
140 1.1295565366744995
141 1.2331953048706055
142 1.2736420631408691
143 1.2316242456436157
144 1.1949180364608765
145 1.1749765872955322
146 1.2425864934921265
147 1.1475027799606323
148 1.318670630455017
149 1.0317583084106445
150 1.0905201435089111
151 1.1935532093048096
152 1.2163503170013428
153 1.1305214166641235
154 1.1677601337432861
155 1.1872345209121704
156 1.3555362224578857
157 1.116507649421692
158 1.2409805059432983
159 1.1060198545455933
160 1.2264541387557983
161 1.0366852283477783
162 0.9704899787902832
163 1.0373648405075073
164 1.1358047723770142
165 1.1038317680358887
166 1.0201014280319214
167 1.1284123659133911
168 1.0697077512741089
169 1.027155876159668
170 1.2332173585891724
171 1.1152023077011108
172 1.0815577507019043
173 1.0891520977020264
174 1.0281354188919067
175 1.0651394128799438
176 1.1889843940734863
177 1.2936254739761353
178 1.290764331817627
179 1.2668349742889404
180 1.1175262928009033
181 1.0615513324737549
182 1.1477869749069214
183 1.2019630670547485
184 1.0269627571105957
185 1.0682101249694824
186 1.0020965337753296
187 1.1365550756454468
188 1.142543911933899
189 1.1844606399536133
190 1.1392768621444702
191 1.0955040454864502
192 1.194412350654602
193 1.2974590063095093
194 1.276748776435852
195 1.0375773906707764
196 0.9683144092559814
197 1.165903091430664
198 1.0586429834365845
199 1.2042131423950195
.............
370.95527852512896 150.0937744360417 509.3990252818912
.............
0 1.181652307510376
Train Epoch: 3 [0/20000 (0%)]	Loss: 1.181652
1 1.3144352436065674
2 1.2628693580627441
3 1.1483265161514282
4 1.1566098928451538
5 1.3773075342178345
6 0.9285697937011719
7 1.2191224098205566
8 1.0365746021270752
9 1.261461615562439
10 0.9731846451759338
11 1.1395472288131714
12 1.1044971942901611
13 1.0824099779129028
14 1.151042103767395
15 1.1311382055282593
16 1.1564959287643433
17 1.0187182426452637
18 1.2867133617401123
19 1.1105468273162842
20 1.2525453567504883
21 1.1452021598815918
22 1.034176230430603
23 1.2339998483657837
24 1.1499282121658325
25 1.0603549480438232
26 1.2173506021499634
27 1.1585758924484253
28 1.0844752788543701
29 1.0723826885223389
30 1.0526450872421265
31 1.0808197259902954
32 1.0781071186065674
33 1.1492877006530762
34 1.0957443714141846
35 1.214675784111023
36 0.999325692653656
37 1.0962519645690918
38 1.0317699909210205
39 1.185990571975708
40 0.9979564547538757
41 1.177111268043518
42 1.348650336265564
43 0.9734289646148682
44 0.9765946865081787
45 1.1246109008789062
46 1.2800618410110474
47 1.152601718902588
48 1.3297858238220215
49 1.229917287826538
50 1.2149817943572998
51 1.1276257038116455
52 1.2188044786453247
53 1.0826354026794434
54 0.9143755435943604
55 1.0554065704345703
56 1.2320520877838135
57 1.1117974519729614
58 1.177217960357666
59 1.2184045314788818
60 1.2513121366500854
61 1.1738148927688599
62 1.2059742212295532
63 1.0335261821746826
64 1.14015793800354
65 1.162233829498291
66 1.006176471710205
67 1.2017940282821655
68 1.0908108949661255
69 1.1584486961364746
70 1.067702054977417
71 1.3051015138626099
72 1.124336838722229
73 1.0420221090316772
74 1.2020506858825684
75 1.0874758958816528
76 1.0082703828811646
77 0.9539879560470581
78 1.200565218925476
79 1.1414352655410767
80 1.1261625289916992
81 1.1011817455291748
82 1.1853063106536865
83 1.0300345420837402
84 0.9570619463920593
85 1.1773653030395508
86 1.2836509943008423
87 1.0424714088439941
88 0.9185712933540344
89 1.0949616432189941
90 1.2638269662857056
91 1.3772083520889282
92 1.2807499170303345
93 1.132369041442871
94 1.199730396270752
95 1.0172357559204102
96 1.121864676475525
97 1.3398118019104004
98 1.1272815465927124
99 1.1952301263809204
100 1.008161187171936
Train Epoch: 3 [10000/20000 (50%)]	Loss: 1.008161
101 1.251571774482727
102 1.0821946859359741
103 1.0868548154830933
104 1.1704516410827637
105 1.1563889980316162
106 1.1437580585479736
107 1.1558195352554321
108 1.0043435096740723
109 1.3019981384277344
110 1.1378264427185059
111 1.0512747764587402
112 1.1762012243270874
113 1.220799446105957
114 0.9759377837181091
115 1.1896835565567017
116 1.20755934715271
117 1.1768100261688232
118 0.986764132976532
119 1.0171902179718018
120 1.2483525276184082
121 1.244705080986023
122 1.1090298891067505
123 1.2937465906143188
124 1.0784817934036255
125 1.2054799795150757
126 1.216189980506897
127 1.2379146814346313
128 0.9554614424705505
129 1.2339078187942505
130 1.116805076599121
131 1.0840747356414795
132 1.0960876941680908
133 1.03416109085083
134 1.0494076013565063
135 0.9953435659408569
136 1.138750433921814
137 0.9164340496063232
138 1.265787959098816
139 1.1245789527893066
140 1.0650988817214966
141 1.2241469621658325
142 1.2082135677337646
143 1.1577599048614502
144 1.1975599527359009
145 1.1415481567382812
146 1.205277442932129
147 1.0532636642456055
148 1.2158221006393433
149 0.9417615532875061
150 1.120072364807129
151 1.1235289573669434
152 1.1636534929275513
153 1.1085309982299805
154 1.1469194889068604
155 1.1302974224090576
156 1.3273922204971313
157 1.0642949342727661
158 1.158285140991211
159 1.073671579360962
160 1.1755088567733765
161 0.9653091430664062
162 0.9016586542129517
163 0.9725147485733032
164 1.0542511940002441
165 1.0729042291641235
166 0.9498426914215088
167 1.0642216205596924
168 0.9806478023529053
169 0.9703976511955261
170 1.1657898426055908
171 1.0257036685943604
172 1.0144214630126953
173 1.0224498510360718
174 0.9964061975479126
175 0.9688530564308167
176 1.1464539766311646
177 1.2115492820739746
178 1.2133762836456299
179 1.170531988143921
180 1.0619317293167114
181 1.0212035179138184
182 1.0888310670852661
183 1.1279973983764648
184 0.9841207265853882
185 1.0234856605529785
186 0.938771665096283
187 1.0798125267028809
188 1.073569655418396
189 1.1424553394317627
190 1.0706582069396973
191 1.038771629333496
192 1.1418092250823975
193 1.2541933059692383
194 1.2256066799163818
195 0.9634925127029419
196 0.923475980758667
197 1.083827257156372
198 1.0166186094284058
199 1.1659966707229614
.............
764.9808067604899 343.6102988515049 1081.4438339211047
.............
0 1.1239080429077148
Train Epoch: 4 [0/20000 (0%)]	Loss: 1.123908
1 1.2777575254440308
2 1.2146438360214233
3 1.1301488876342773
4 1.096980333328247
5 1.3301869630813599
6 0.8990371823310852
7 1.1701369285583496
8 0.9835756421089172
9 1.209144949913025
10 0.9181461334228516
11 1.074032187461853
12 1.0555322170257568
13 1.0169628858566284
14 1.135327696800232
15 1.1025563478469849
16 1.0908503532409668
17 0.9497843980789185
18 1.2727208137512207
19 1.0590100288391113
20 1.2053635120391846
21 1.0885900259017944
22 0.9714178442955017
23 1.1829754114151
24 1.1014842987060547
25 1.011785864830017
26 1.1950997114181519
27 1.1051478385925293
28 1.098448395729065
29 1.064131498336792
30 1.03013014793396
31 1.1107215881347656
32 1.0287156105041504
33 1.125687599182129
34 1.0737072229385376
35 1.181829571723938
36 1.0299755334854126
37 1.0977438688278198
38 1.0114036798477173
39 1.1498496532440186
40 0.9699191451072693
41 1.1484607458114624
42 1.3136858940124512
43 0.9197490215301514
44 0.9571859836578369
45 1.1012718677520752
46 1.2170138359069824
47 1.1209739446640015
48 1.2865815162658691
49 1.1412290334701538
50 1.1426281929016113
51 1.0743502378463745
52 1.1873785257339478
53 1.030624508857727
54 0.9155046343803406
55 1.0196913480758667
56 1.1417841911315918
57 1.0564484596252441
58 1.1200599670410156
59 1.1678361892700195
60 1.1713078022003174
61 1.1218180656433105
62 1.153210997581482
63 0.9960898756980896
64 1.0733749866485596
65 1.0981887578964233
66 0.9691409468650818
67 1.1930381059646606
68 1.0240330696105957
69 1.132386565208435
70 1.037304401397705
71 1.2871079444885254
72 1.1006895303726196
73 1.0534498691558838
74 1.1716281175613403
75 1.090192198753357
76 0.9747823476791382
77 0.9457030296325684
78 1.1980650424957275
79 1.1123331785202026
80 1.0708379745483398
81 1.0752160549163818
82 1.1384696960449219
83 0.9884540438652039
84 0.9635522961616516
85 1.1414421796798706
86 1.27980375289917
87 1.0095765590667725
88 0.9001829624176025
89 1.0867773294448853
90 1.2703970670700073
91 1.356523871421814
92 1.2764242887496948
93 1.13560152053833
94 1.1721245050430298
95 1.0037938356399536
96 1.1463474035263062
97 1.291711688041687
98 1.0922727584838867
99 1.171872615814209
100 0.9837847948074341
Train Epoch: 4 [10000/20000 (50%)]	Loss: 0.983785
101 1.2221835851669312
102 1.0744212865829468
103 1.1182892322540283
104 1.139205813407898
105 1.1232129335403442
106 1.1080145835876465
107 1.1318049430847168
108 0.9967504739761353
109 1.2879656553268433
110 1.1007615327835083
111 1.0312583446502686
112 1.1438682079315186
113 1.1928520202636719
114 0.9625247120857239
115 1.1563770771026611
116 1.1627593040466309
117 1.140390396118164
118 0.9914388060569763
119 0.9915679693222046
120 1.2145023345947266
121 1.2374402284622192
122 1.0730630159378052
123 1.2782964706420898
124 1.0435672998428345
125 1.1850380897521973
126 1.2110344171524048
127 1.2225667238235474
128 0.9533448815345764
129 1.1921297311782837
130 1.104944109916687
131 1.0475795269012451
132 1.037932276725769
133 0.9969667196273804
134 1.029316782951355
135 0.9805443286895752
136 1.137162446975708
137 0.8875632286071777
138 1.2470532655715942
139 1.1153219938278198
140 1.0539113283157349
141 1.2332857847213745
142 1.1803396940231323
143 1.120287299156189
144 1.190935730934143
145 1.134095549583435
146 1.1991214752197266
147 1.0109107494354248
148 1.1877104043960571
149 0.9242420196533203
150 1.1091197729110718
151 1.1377034187316895
152 1.1669937372207642
153 1.0773203372955322
154 1.0815132856369019
155 1.0949254035949707
156 1.3078293800354004
157 1.0725884437561035
158 1.14659583568573
159 1.0901706218719482
160 1.1776381731033325
161 0.9498522877693176
162 0.9138570427894592
163 0.9965518712997437
164 1.04827082157135
165 1.0443058013916016
166 0.9218108654022217
167 1.040267825126648
168 0.9830996990203857
169 0.9565994739532471
170 1.15509831905365
171 1.017592191696167
172 0.9822575449943542
173 0.9963442087173462
174 1.0029280185699463
175 0.9845712780952454
176 1.1639313697814941
177 1.1791579723358154
178 1.1990927457809448
179 1.1690865755081177
180 1.0525615215301514
181 1.0204969644546509
182 1.059880018234253
183 1.104235053062439
184 0.9680374264717102
185 1.0126209259033203
186 0.9266915321350098
187 1.0707906484603882
188 1.0494797229766846
189 1.1250005960464478
190 1.0517170429229736
191 1.0156164169311523
192 1.1123747825622559
193 1.2126137018203735
194 1.197805643081665
195 0.9364954233169556
196 0.9086057543754578
197 1.0534509420394897
198 0.9933723211288452
199 1.1371098756790161
.............
1553.7540466040373 730.5155905410647 2225.8874999061227
.............
0 1.09152090549469
Train Epoch: 5 [0/20000 (0%)]	Loss: 1.091521
1 1.2734415531158447
2 1.1927345991134644
3 1.116723895072937
4 1.0536612272262573
5 1.3028944730758667
6 0.8834163546562195
7 1.1466448307037354
8 0.9683687090873718
9 1.1913701295852661
10 0.9113099575042725
11 1.0457937717437744
12 1.0402199029922485
13 1.0082277059555054
14 1.1279711723327637
15 1.0691933631896973
16 1.063391923904419
17 0.9201850891113281
18 1.2646222114562988
19 1.0269428491592407
20 1.1889837980270386
21 1.062235713005066
22 0.9408274292945862
23 1.1562156677246094
24 1.0921058654785156
25 0.9863014817237854
26 1.188818335533142
27 1.0646499395370483
28 1.0690995454788208
29 1.0535165071487427
30 0.9727559089660645
31 1.0550702810287476
32 1.006558895111084
33 1.0852868556976318
34 1.0393052101135254
35 1.176676630973816
36 0.9786150455474854
37 1.0720586776733398
38 0.997149646282196
39 1.1804808378219604
40 0.9555891156196594
41 1.0983614921569824
42 1.2936707735061646
43 0.9124534130096436
44 0.9324855208396912
45 1.0870916843414307
46 1.2522588968276978
47 1.0631026029586792
48 1.2875070571899414
49 1.1279176473617554
50 1.1956164836883545
51 1.0923309326171875
52 1.1301989555358887
53 1.0319502353668213
54 0.9187268614768982
55 1.0069124698638916
56 1.121100664138794
57 1.0507301092147827
58 1.1348727941513062
59 1.1492514610290527
60 1.137230634689331
61 1.1221166849136353
62 1.1510634422302246
63 0.948050320148468
64 1.0338244438171387
65 1.0577369928359985
66 0.9444829821586609
67 1.163774013519287
68 1.0196713209152222
69 1.0906718969345093
70 0.9772728681564331
71 1.2509568929672241
72 1.0925101041793823
73 1.0231186151504517
74 1.1478480100631714
75 1.0537093877792358
76 0.9699792265892029
77 0.9368649125099182
78 1.1745364665985107
79 1.0788415670394897
80 1.0569109916687012
81 1.0621039867401123
82 1.1223655939102173
83 0.9692216515541077
84 0.9002194404602051
85 1.1208585500717163
86 1.2241121530532837
87 0.9731397032737732
88 0.8926246762275696
89 1.0535545349121094
90 1.244457721710205
91 1.3424464464187622
92 1.2600903511047363
93 1.0991588830947876
94 1.154048204421997
95 0.9668094515800476
96 1.0955172777175903
97 1.2251105308532715
98 1.0790971517562866
99 1.1300184726715088
100 0.9435478448867798
Train Epoch: 5 [10000/20000 (50%)]	Loss: 0.943548
101 1.1920071840286255
102 1.0380386114120483
103 1.067600965499878
104 1.1176044940948486
105 1.1007676124572754
106 1.0688849687576294
107 1.1105356216430664
108 0.9856219291687012
109 1.2587038278579712
110 1.0831698179244995
111 1.0190719366073608
112 1.0984020233154297
113 1.187909722328186
114 0.9444127082824707
115 1.1387438774108887
116 1.1371136903762817
117 1.1077582836151123
118 0.9753753542900085
119 0.9604794979095459
120 1.1599924564361572
121 1.2444756031036377
122 1.0427579879760742
123 1.2153164148330688
124 1.022480845451355
125 1.1631035804748535
126 1.186875581741333
127 1.1724810600280762
128 0.9519118666648865
129 1.1360398530960083
130 1.0867384672164917
131 1.0298079252243042
132 0.9807079434394836
133 0.9599394798278809
134 1.0064986944198608
135 0.9597437977790833
136 1.1123759746551514
137 0.8627517819404602
138 1.2183035612106323
139 1.062044382095337
140 1.0197486877441406
141 1.2185174226760864
142 1.1524937152862549
143 1.095232367515564
144 1.160233974456787
145 1.1063110828399658
146 1.17466402053833
147 0.9812256693840027
148 1.1715461015701294
149 0.8870192766189575
150 1.0906978845596313
151 1.1358678340911865
152 1.1264126300811768
153 1.0526604652404785
154 1.0686206817626953
155 1.0525363683700562
156 1.2939053773880005
157 1.091546893119812
158 1.1162029504776
159 1.0718597173690796
160 1.1819885969161987
161 0.9573832154273987
162 0.8992987871170044
163 1.0477811098098755
164 1.073441505432129
165 1.0318613052368164
166 0.9210751056671143
167 1.028195858001709
168 0.9782640337944031
169 0.9593647122383118
170 1.1528738737106323
171 1.0141911506652832
172 0.9892817139625549
173 0.9715307354927063
174 0.9897840619087219
175 0.9597698450088501
176 1.1528904438018799
177 1.1777130365371704
178 1.173749566078186
179 1.1566746234893799
180 1.043175458908081
181 1.0028437376022339
182 1.0438534021377563
183 1.0737637281417847
184 0.9570320248603821
185 0.9959947466850281
186 0.9022830724716187
187 1.0532593727111816
188 1.0348275899887085
189 1.1095571517944336
190 1.0286885499954224
191 1.0012575387954712
192 1.08659827709198
193 1.1711792945861816
194 1.1676952838897705
195 0.9169398546218872
196 0.8950598835945129
197 1.0208547115325928
198 0.9694012403488159
199 1.1188557147979736
.............
3131.348819838837 1504.3689064215869 4514.41974651441
.............
3131.348819838837 1504.3689064215869 4514.41974651441
.............
