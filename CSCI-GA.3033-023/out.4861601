0 2.846029281616211
Train Epoch: 1 [0/20000 (0%)]	Loss: 2.846029
1 2.830829381942749
2 2.8042819499969482
3 2.7515153884887695
4 2.728139877319336
5 2.6632540225982666
6 2.5635619163513184
7 2.5055978298187256
8 2.384932041168213
9 2.311173439025879
10 2.1299896240234375
11 1.9831771850585938
12 1.827309250831604
13 1.9343369007110596
14 1.8543919324874878
15 1.9113301038742065
16 1.9000163078308105
17 1.9384406805038452
18 1.7175391912460327
19 1.7805911302566528
20 1.985146164894104
21 1.8626987934112549
22 1.550979495048523
23 1.7604237794876099
24 1.652970552444458
25 1.752439022064209
26 1.8369660377502441
27 1.8052237033843994
28 1.5011639595031738
29 1.6689400672912598
30 1.6495403051376343
31 1.6702470779418945
32 1.6203652620315552
33 1.5964959859848022
34 1.6563291549682617
35 1.7498151063919067
36 1.538255214691162
37 1.6360610723495483
38 1.527821660041809
39 1.5664515495300293
40 1.5837578773498535
41 1.5980634689331055
42 1.6554065942764282
43 1.529350996017456
44 1.4302259683609009
45 1.4681321382522583
46 1.7198492288589478
47 1.6022460460662842
48 1.6763805150985718
49 1.6036192178726196
50 1.5247350931167603
51 1.5343705415725708
52 1.571077585220337
53 1.490858793258667
54 1.3043866157531738
55 1.5626535415649414
56 1.7655678987503052
57 1.5630218982696533
58 1.467686653137207
59 1.6191521883010864
60 1.675482988357544
61 1.6048402786254883
62 1.5607690811157227
63 1.544399380683899
64 1.6186376810073853
65 1.5859742164611816
66 1.4596154689788818
67 1.5373659133911133
68 1.5062611103057861
69 1.561956763267517
70 1.4250786304473877
71 1.619911551475525
72 1.4296282529830933
73 1.4157212972640991
74 1.3919175863265991
75 1.4050310850143433
76 1.3982292413711548
77 1.3234602212905884
78 1.4797154664993286
79 1.510868787765503
80 1.3661631345748901
81 1.4361045360565186
82 1.527109980583191
83 1.468156337738037
84 1.247138500213623
85 1.4926400184631348
86 1.6229480504989624
87 1.4510815143585205
88 1.3166013956069946
89 1.4193190336227417
90 1.5326215028762817
91 1.6163198947906494
92 1.5824482440948486
93 1.4560073614120483
94 1.4516574144363403
95 1.3240251541137695
96 1.3949002027511597
97 1.6215910911560059
98 1.5779157876968384
99 1.4040718078613281
100 1.3499996662139893
Train Epoch: 1 [10000/20000 (50%)]	Loss: 1.350000
101 1.5077545642852783
102 1.3632299900054932
103 1.3046504259109497
104 1.4748170375823975
105 1.5477304458618164
106 1.3932970762252808
107 1.4661662578582764
108 1.3827952146530151
109 1.5454723834991455
110 1.4518558979034424
111 1.3472251892089844
112 1.5532145500183105
113 1.4819377660751343
114 1.1971445083618164
115 1.3899656534194946
116 1.3488446474075317
117 1.4056763648986816
118 1.2582277059555054
119 1.2530254125595093
120 1.4714468717575073
121 1.4079406261444092
122 1.3389315605163574
123 1.4825663566589355
124 1.2442305088043213
125 1.3319276571273804
126 1.3177025318145752
127 1.4137556552886963
128 1.1438475847244263
129 1.4087218046188354
130 1.2543944120407104
131 1.3048595190048218
132 1.2839773893356323
133 1.2853803634643555
134 1.3110159635543823
135 1.2057820558547974
136 1.2379564046859741
137 1.1316508054733276
138 1.4053956270217896
139 1.120099425315857
140 1.300338864326477
141 1.360016942024231
142 1.407020092010498
143 1.3257532119750977
144 1.293398141860962
145 1.312495231628418
146 1.3267055749893188
147 1.2878315448760986
148 1.431175708770752
149 1.187963843345642
150 1.191993236541748
151 1.3252692222595215
152 1.3145602941513062
153 1.239240050315857
154 1.3297362327575684
155 1.373223900794983
156 1.4137119054794312
157 1.1853821277618408
158 1.3945214748382568
159 1.2008373737335205
160 1.3291362524032593
161 1.1391069889068604
162 1.1056408882141113
163 1.128963828086853
164 1.226942539215088
165 1.1744366884231567
166 1.10926353931427
167 1.244438648223877
168 1.1971553564071655
169 1.173918604850769
170 1.32942795753479
171 1.2007715702056885
172 1.2189557552337646
173 1.1697348356246948
174 1.1408859491348267
175 1.1299279928207397
176 1.2990983724594116
177 1.4246199131011963
178 1.3508005142211914
179 1.3362927436828613
180 1.220839023590088
181 1.1965943574905396
182 1.2297190427780151
183 1.3184744119644165
184 1.2265381813049316
185 1.1821309328079224
186 1.1059744358062744
187 1.2062336206436157
188 1.2472691535949707
189 1.327243447303772
190 1.2668449878692627
191 1.2719556093215942
192 1.3887693881988525
193 1.3643136024475098
194 1.2982664108276367
195 1.2934857606887817
196 1.0783771276474
197 1.2751588821411133
198 1.1800110340118408
199 1.3414959907531738
.............
167.53357314318419 155.96119533106685 4.471780512481928
.............
./lab1.pytorch:80: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  output = F.log_softmax(self.linear3(z))
0 1.3352943658828735
Train Epoch: 2 [0/20000 (0%)]	Loss: 1.335294
1 1.401100754737854
2 1.327425241470337
3 1.240580439567566
4 1.2295838594436646
5 1.4869998693466187
6 1.081791877746582
7 1.337247610092163
8 1.1814677715301514
9 1.3498950004577637
10 1.0684911012649536
11 1.2478346824645996
12 1.1716254949569702
13 1.1896178722381592
14 1.2051939964294434
15 1.2661411762237549
16 1.2627098560333252
17 1.241863489151001
18 1.339781641960144
19 1.1879063844680786
20 1.3581451177597046
21 1.2701512575149536
22 1.1796467304229736
23 1.347144603729248
24 1.300425410270691
25 1.1553646326065063
26 1.3254755735397339
27 1.27108895778656
28 1.1561628580093384
29 1.1425689458847046
30 1.1592823266983032
31 1.2372143268585205
32 1.200499176979065
33 1.240796446800232
34 1.1809834241867065
35 1.3060611486434937
36 1.1354888677597046
37 1.1650899648666382
38 1.1317847967147827
39 1.3002138137817383
40 1.0770690441131592
41 1.2746341228485107
42 1.3826408386230469
43 1.082711935043335
44 1.0831725597381592
45 1.1981145143508911
46 1.3274078369140625
47 1.1926161050796509
48 1.4298869371414185
49 1.278014898300171
50 1.2973898649215698
51 1.1964068412780762
52 1.2604867219924927
53 1.1878987550735474
54 1.0155444145202637
55 1.0887912511825562
56 1.2999472618103027
57 1.1792625188827515
58 1.238507866859436
59 1.2749568223953247
60 1.29024076461792
61 1.1889469623565674
62 1.3037399053573608
63 1.1899614334106445
64 1.1714141368865967
65 1.1731884479522705
66 1.152580738067627
67 1.4000968933105469
68 1.1108717918395996
69 1.2616313695907593
70 1.24192476272583
71 1.4339255094528198
72 1.1998611688613892
73 1.107884407043457
74 1.2283685207366943
75 1.2401251792907715
76 1.187254786491394
77 1.0226496458053589
78 1.2503620386123657
79 1.2737579345703125
80 1.304563045501709
81 1.2403497695922852
82 1.2466386556625366
83 1.222935676574707
84 0.9734659790992737
85 1.2791945934295654
86 1.3961483240127563
87 1.189561128616333
88 1.0229490995407104
89 1.20521080493927
90 1.3354198932647705
91 1.423183560371399
92 1.3450607061386108
93 1.23796808719635
94 1.288313388824463
95 1.1049623489379883
96 1.1650408506393433
97 1.380287528038025
98 1.2049362659454346
99 1.2403398752212524
100 1.1178990602493286
Train Epoch: 2 [10000/20000 (50%)]	Loss: 1.117899
101 1.3167682886123657
102 1.0785423517227173
103 1.0970304012298584
104 1.2577943801879883
105 1.225867748260498
106 1.1684597730636597
107 1.2367336750030518
108 1.1285873651504517
109 1.3452032804489136
110 1.2511214017868042
111 1.1493512392044067
112 1.3165030479431152
113 1.228705883026123
114 1.106589913368225
115 1.2832783460617065
116 1.2042564153671265
117 1.2304648160934448
118 1.1769089698791504
119 1.0888352394104004
120 1.293603777885437
121 1.3092243671417236
122 1.226637363433838
123 1.3719377517700195
124 1.133144497871399
125 1.2096489667892456
126 1.2268085479736328
127 1.3003441095352173
128 1.001250982284546
129 1.2925220727920532
130 1.109872817993164
131 1.1932389736175537
132 1.1348278522491455
133 1.0884253978729248
134 1.1145120859146118
135 1.0350961685180664
136 1.1580020189285278
137 0.9910784959793091
138 1.2970800399780273
139 1.0358754396438599
140 1.1140245199203491
141 1.2269295454025269
142 1.2697900533676147
143 1.211107611656189
144 1.1784157752990723
145 1.1727203130722046
146 1.248916745185852
147 1.138222098350525
148 1.305309772491455
149 1.016472339630127
150 1.0970675945281982
151 1.1851176023483276
152 1.2046589851379395
153 1.121229648590088
154 1.1740220785140991
155 1.1822108030319214
156 1.3470375537872314
157 1.1011346578598022
158 1.2364426851272583
159 1.10695219039917
160 1.2207783460617065
161 1.0220955610275269
162 0.9598867893218994
163 1.0342122316360474
164 1.1295843124389648
165 1.0867829322814941
166 0.9949138164520264
167 1.1176313161849976
168 1.061285138130188
169 1.0133765935897827
170 1.2135214805603027
171 1.0977767705917358
172 1.073945164680481
173 1.079055905342102
174 1.0208637714385986
175 1.0371296405792236
176 1.1789038181304932
177 1.2838646173477173
178 1.2776134014129639
179 1.2566311359405518
180 1.110072374343872
181 1.0587012767791748
182 1.1377793550491333
183 1.1848701238632202
184 1.017198920249939
185 1.0621830224990845
186 0.9911373257637024
187 1.1232454776763916
188 1.1322349309921265
189 1.1741353273391724
190 1.129763126373291
191 1.0963873863220215
192 1.1943325996398926
193 1.2886879444122314
194 1.271333932876587
195 1.022326946258545
196 0.9623698592185974
197 1.1543300151824951
198 1.0529168844223022
199 1.1999905109405518
.............
654.0960546154529 359.89541911520064 17.299353564158082
.............
0 1.1739003658294678
Train Epoch: 3 [0/20000 (0%)]	Loss: 1.173900
1 1.3102705478668213
2 1.2609013319015503
3 1.1488282680511475
4 1.1582345962524414
5 1.36598801612854
6 0.9199756383895874
7 1.2166895866394043
8 1.0250136852264404
9 1.2543985843658447
10 0.9558475613594055
11 1.1279878616333008
12 1.1037039756774902
13 1.0607385635375977
14 1.143429160118103
15 1.1333324909210205
16 1.1512569189071655
17 1.0062329769134521
18 1.282478928565979
19 1.1004645824432373
20 1.2609742879867554
21 1.130812168121338
22 1.0261545181274414
23 1.2239183187484741
24 1.1411837339401245
25 1.05635666847229
26 1.2194790840148926
27 1.1487585306167603
28 1.089444637298584
29 1.0763137340545654
30 1.055985450744629
31 1.09578275680542
32 1.0646312236785889
33 1.1389673948287964
34 1.0971280336380005
35 1.2135701179504395
36 0.9945562481880188
37 1.0911035537719727
38 1.0255422592163086
39 1.177657127380371
40 0.9879968166351318
41 1.1787570714950562
42 1.3321800231933594
43 0.9470012187957764
44 0.9664271473884583
45 1.1214327812194824
46 1.264693260192871
47 1.1304770708084106
48 1.3100440502166748
49 1.222639799118042
50 1.1888461112976074
51 1.1080713272094727
52 1.2441678047180176
53 1.0544532537460327
54 0.9054603576660156
55 1.0583833456039429
56 1.2105457782745361
57 1.0996018648147583
58 1.1502163410186768
59 1.212573528289795
60 1.25678288936615
61 1.1455475091934204
62 1.1951693296432495
63 1.0593466758728027
64 1.1406192779541016
65 1.1413533687591553
66 1.0014203786849976
67 1.2169787883758545
68 1.0695691108703613
69 1.1534178256988525
70 1.0907667875289917
71 1.3071763515472412
72 1.1118638515472412
73 1.0641406774520874
74 1.1891589164733887
75 1.091691255569458
76 1.0032289028167725
77 0.9540925621986389
78 1.1994856595993042
79 1.1325832605361938
80 1.0999568700790405
81 1.1141369342803955
82 1.1728272438049316
83 1.0122942924499512
84 0.9719908833503723
85 1.1721705198287964
86 1.3098771572113037
87 1.0405462980270386
88 0.913109302520752
89 1.09203040599823
90 1.2766363620758057
91 1.3774317502975464
92 1.274651288986206
93 1.1457198858261108
94 1.1960978507995605
95 1.0168631076812744
96 1.1466236114501953
97 1.356194257736206
98 1.1325507164001465
99 1.188328504562378
100 1.0042871236801147
Train Epoch: 3 [10000/20000 (50%)]	Loss: 1.004287
101 1.2620501518249512
102 1.0928716659545898
103 1.1087274551391602
104 1.1668920516967773
105 1.1488099098205566
106 1.1333163976669312
107 1.1549500226974487
108 1.0014456510543823
109 1.3151494264602661
110 1.1314715147018433
111 1.045494556427002
112 1.1757301092147827
113 1.2056608200073242
114 0.9622920155525208
115 1.1896799802780151
116 1.198238730430603
117 1.1770082712173462
118 0.9809790253639221
119 1.0208667516708374
120 1.2434898614883423
121 1.2471110820770264
122 1.1111843585968018
123 1.2989026308059692
124 1.0896689891815186
125 1.197554588317871
126 1.216002106666565
127 1.2361204624176025
128 0.9559454321861267
129 1.2290011644363403
130 1.0968806743621826
131 1.0876891613006592
132 1.0877894163131714
133 1.021929383277893
134 1.0569324493408203
135 0.9901460409164429
136 1.123510718345642
137 0.9084168076515198
138 1.2684537172317505
139 1.1298667192459106
140 1.0653446912765503
141 1.219936490058899
142 1.2003250122070312
143 1.1630959510803223
144 1.197014570236206
145 1.140316128730774
146 1.209197759628296
147 1.0460352897644043
148 1.2094818353652954
149 0.9371563792228699
150 1.1464190483093262
151 1.1260063648223877
152 1.170202612876892
153 1.1118770837783813
154 1.1437840461730957
155 1.123978614807129
156 1.3230984210968018
157 1.0664758682250977
158 1.1605321168899536
159 1.0661038160324097
160 1.176180362701416
161 0.9584009647369385
162 0.8981841206550598
163 0.974831223487854
164 1.054498553276062
165 1.0564936399459839
166 0.935818612575531
167 1.053204894065857
168 0.9821077585220337
169 0.9658275842666626
170 1.1663901805877686
171 1.0252676010131836
172 1.0146669149398804
173 1.0123201608657837
174 0.9907159209251404
175 0.9750420451164246
176 1.1449602842330933
177 1.2051523923873901
178 1.2136482000350952
179 1.1740037202835083
180 1.058801293373108
181 1.0194408893585205
182 1.08706796169281
183 1.123419165611267
184 0.9820364117622375
185 1.0176550149917603
186 0.93450927734375
187 1.0658268928527832
188 1.0648093223571777
189 1.1268216371536255
190 1.0690624713897705
191 1.0339869260787964
192 1.1280951499938965
193 1.231236219406128
194 1.2172220945358276
195 0.9577074646949768
196 0.9213190674781799
197 1.0705039501190186
198 1.0085021257400513
199 1.1594263315200806
.............
1635.7736360561103 766.220044830814 42.654733492061496
.............
0 1.1106184720993042
Train Epoch: 4 [0/20000 (0%)]	Loss: 1.110618
1 1.2751237154006958
2 1.2140657901763916
3 1.1257076263427734
4 1.0942703485488892
5 1.3208340406417847
6 0.8929497599601746
7 1.1651091575622559
8 0.9786134362220764
9 1.2051178216934204
10 0.909496009349823
11 1.0648099184036255
12 1.051419734954834
13 1.009670615196228
14 1.1327768564224243
15 1.0995177030563354
16 1.0752214193344116
17 0.9465067982673645
18 1.2769874334335327
19 1.0483958721160889
20 1.198946475982666
21 1.0814080238342285
22 0.9602895975112915
23 1.1761326789855957
24 1.0978854894638062
25 1.002851963043213
26 1.1816707849502563
27 1.094791293144226
28 1.0834136009216309
29 1.0537601709365845
30 1.040493130683899
31 1.093893051147461
32 1.0327647924423218
33 1.117337703704834
34 1.0522902011871338
35 1.1720364093780518
36 1.0364896059036255
37 1.085080862045288
38 1.004930019378662
39 1.1432722806930542
40 0.958306074142456
41 1.1203548908233643
42 1.3019440174102783
43 0.8955028653144836
44 0.9423768520355225
45 1.1001534461975098
46 1.2048660516738892
47 1.097731590270996
48 1.2846111059188843
49 1.1141165494918823
50 1.1286548376083374
51 1.0729445219039917
52 1.1668956279754639
53 1.010642647743225
54 0.9074243307113647
55 1.020094633102417
56 1.1398180723190308
57 1.0503504276275635
58 1.121293544769287
59 1.161224603652954
60 1.166192889213562
61 1.1123454570770264
62 1.1508095264434814
63 1.0043747425079346
64 1.0645420551300049
65 1.0825369358062744
66 0.966768741607666
67 1.194034457206726
68 1.0136390924453735
69 1.130626916885376
70 1.033792495727539
71 1.2857704162597656
72 1.0972071886062622
73 1.0491421222686768
74 1.158788800239563
75 1.0854419469833374
76 0.9754980206489563
77 0.9433332681655884
78 1.185388445854187
79 1.1039336919784546
80 1.058637261390686
81 1.0778801441192627
82 1.1346949338912964
83 0.9785433411598206
84 0.9509180188179016
85 1.1313728094100952
86 1.268640160560608
87 0.9998407959938049
88 0.9004396200180054
89 1.0699528455734253
90 1.2604115009307861
91 1.3545302152633667
92 1.2686535120010376
93 1.129870057106018
94 1.1657326221466064
95 0.9894051551818848
96 1.1365594863891602
97 1.273209810256958
98 1.0884989500045776
99 1.1535972356796265
100 0.9688922762870789
Train Epoch: 4 [10000/20000 (50%)]	Loss: 0.968892
101 1.2122529745101929
102 1.0599873065948486
103 1.090212345123291
104 1.13042414188385
105 1.1082792282104492
106 1.0864120721817017
107 1.1217117309570312
108 0.9951984882354736
109 1.2868694067001343
110 1.0980793237686157
111 1.0266742706298828
112 1.1226962804794312
113 1.187476634979248
114 0.9535476565361023
115 1.1524133682250977
116 1.1509970426559448
117 1.132540225982666
118 0.9761361479759216
119 0.9808608889579773
120 1.1944314241409302
121 1.2413042783737183
122 1.0570627450942993
123 1.24331533908844
124 1.0386697053909302
125 1.1787638664245605
126 1.1990009546279907
127 1.1944468021392822
128 0.9487746357917786
129 1.1552940607070923
130 1.094982385635376
131 1.0378721952438354
132 1.0138819217681885
133 0.9803981781005859
134 1.0123257637023926
135 0.9670087695121765
136 1.1122260093688965
137 0.8753779530525208
138 1.232202172279358
139 1.081007480621338
140 1.0275607109069824
141 1.2177777290344238
142 1.1627568006515503
143 1.1167454719543457
144 1.170862078666687
145 1.112191915512085
146 1.1854920387268066
147 0.9957016706466675
148 1.178467869758606
149 0.8965478539466858
150 1.1186434030532837
151 1.1311534643173218
152 1.1364903450012207
153 1.0811872482299805
154 1.108761191368103
155 1.0703693628311157
156 1.2931203842163086
157 1.0659918785095215
158 1.1442463397979736
159 1.075595498085022
160 1.1660263538360596
161 0.9457393884658813
162 0.9067485928535461
163 1.0014762878417969
164 1.0448814630508423
165 1.0435800552368164
166 0.9235508441925049
167 1.0273555517196655
168 0.9658587574958801
169 0.9539964199066162
170 1.1572858095169067
171 1.0081944465637207
172 0.9934390783309937
173 0.9814011454582214
174 0.9730403423309326
175 0.9701919555664062
176 1.1444491147994995
177 1.1905416250228882
178 1.209493637084961
179 1.1628831624984741
180 1.0402470827102661
181 0.9983618259429932
182 1.0622361898422241
183 1.0811442136764526
184 0.9616664052009583
185 1.0012807846069336
186 0.9142064452171326
187 1.0504155158996582
188 1.0387324094772339
189 1.111325740814209
190 1.0417678356170654
191 1.007564663887024
192 1.0947980880737305
193 1.1897369623184204
194 1.1753263473510742
195 0.9244441986083984
196 0.899671733379364
197 1.0326640605926514
198 0.9764949083328247
199 1.12700617313385
.............
3556.4278395324945 1578.93029143475 91.5917827244848
.............
0 1.0787899494171143
Train Epoch: 5 [0/20000 (0%)]	Loss: 1.078790
1 1.263065218925476
2 1.190018892288208
3 1.1026228666305542
4 1.0541739463806152
5 1.2745444774627686
6 0.8723926544189453
7 1.1279780864715576
8 0.9553312659263611
9 1.1727497577667236
10 0.8913342356681824
11 1.031589150428772
12 1.0334199666976929
13 0.9962137341499329
14 1.1181148290634155
15 1.0620102882385254
16 1.0371623039245605
17 0.9053221344947815
18 1.2652837038040161
19 1.0072578191757202
20 1.170837163925171
21 1.0530909299850464
22 0.9224317669868469
23 1.139796257019043
24 1.0803595781326294
25 0.9681476354598999
26 1.1745972633361816
27 1.0428615808486938
28 1.0479704141616821
29 1.0335421562194824
30 0.9622368812561035
31 1.02886164188385
32 0.9878637790679932
33 1.058754324913025
34 1.0230964422225952
35 1.1533141136169434
36 0.9624292254447937
37 1.0554776191711426
38 0.9724957346916199
39 1.1734482049942017
40 0.9334179759025574
41 1.0642157793045044
42 1.2672808170318604
43 0.8781032562255859
44 0.9209818243980408
45 1.068113923072815
46 1.228782296180725
47 1.0323550701141357
48 1.2648125886917114
49 1.1094856262207031
50 1.171263337135315
51 1.0738047361373901
52 1.106354832649231
53 1.0082405805587769
54 0.8838433027267456
55 0.9832862019538879
56 1.0976974964141846
57 1.0352599620819092
58 1.1080988645553589
59 1.1214563846588135
60 1.1310633420944214
61 1.1100860834121704
62 1.1344090700149536
63 0.9652650356292725
64 1.043360710144043
65 1.0381873846054077
66 0.9426361918449402
67 1.1608601808547974
68 1.0174771547317505
69 1.078844428062439
70 0.9848235845565796
71 1.2208714485168457
72 1.0701690912246704
73 1.0062237977981567
74 1.119410753250122
75 1.0360400676727295
76 0.9651578664779663
77 0.9162552356719971
78 1.143951654434204
79 1.0583653450012207
80 1.0365906953811646
81 1.0460567474365234
82 1.1242399215698242
83 0.949877917766571
84 0.8903892636299133
85 1.0954680442810059
86 1.2011204957962036
87 0.9601486325263977
88 0.8930061459541321
89 1.0301525592803955
90 1.2254544496536255
91 1.3322361707687378
92 1.2446240186691284
93 1.0871294736862183
94 1.1404074430465698
95 0.9355707764625549
96 1.0697462558746338
97 1.1835688352584839
98 1.0778218507766724
99 1.1023200750350952
100 0.9158850312232971
Train Epoch: 5 [10000/20000 (50%)]	Loss: 0.915885
101 1.1711090803146362
102 1.0113520622253418
103 1.027981162071228
104 1.101331114768982
105 1.0599145889282227
106 1.0352147817611694
107 1.1088309288024902
108 0.962419867515564
109 1.2498862743377686
110 1.0596715211868286
111 1.009544849395752
112 1.0709292888641357
113 1.183464765548706
114 0.9192142486572266
115 1.1206167936325073
116 1.1140236854553223
117 1.0770087242126465
118 0.9499056339263916
119 0.9472330212593079
120 1.12180757522583
121 1.2237448692321777
122 1.00515878200531
123 1.1367899179458618
124 1.047356128692627
125 1.1361316442489624
126 1.1421008110046387
127 1.1481839418411255
128 0.965272068977356
129 1.0895425081253052
130 1.0529087781906128
131 1.0317400693893433
132 0.9513353109359741
133 0.9309725761413574
134 0.9878223538398743
135 0.9622682332992554
136 1.108931541442871
137 0.8599311709403992
138 1.201109528541565
139 0.9920232892036438
140 0.9843769073486328
141 1.2104278802871704
142 1.139050006866455
143 1.0635641813278198
144 1.0962036848068237
145 1.0680416822433472
146 1.1616902351379395
147 0.9668077230453491
148 1.1682590246200562
149 0.8666208386421204
150 1.0266871452331543
151 1.1148914098739624
152 1.080339789390564
153 1.0453972816467285
154 1.0738632678985596
155 1.0048608779907227
156 1.2653523683547974
157 1.0481600761413574
158 1.0541977882385254
159 1.0441547632217407
160 1.1377946138381958
161 0.9289492964744568
162 0.8824248313903809
163 1.0206613540649414
164 1.023775577545166
165 0.9961115121841431
166 0.9537270069122314
167 1.020980954170227
168 0.9362109303474426
169 0.9157915711402893
170 1.113101840019226
171 0.9834113121032715
172 0.9793723821640015
173 0.9376236200332642
174 0.9336777329444885
175 0.9118808507919312
176 1.1180710792541504
177 1.1679329872131348
178 1.1668882369995117
179 1.1146734952926636
180 1.0319361686706543
181 0.9617838263511658
182 1.0720300674438477
183 1.0476100444793701
184 0.9668986797332764
185 0.9839387536048889
186 0.8765290975570679
187 1.0136678218841553
188 1.0098844766616821
189 1.0842176675796509
190 1.0051710605621338
191 0.9928101897239685
192 1.0486088991165161
193 1.1723788976669312
194 1.1496601104736328
195 0.9042313098907471
196 0.8859917521476746
197 0.9988739490509033
198 0.94829261302948
199 1.0977541208267212
.............
7454.35184433125 3204.6074578538537 190.9045491144061
.............
15 7454.35184433125 3204.6074578538537 190.9045491144061
.............
