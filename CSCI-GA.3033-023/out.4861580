0 2.8162686824798584
Train Epoch: 1 [0/20000 (0%)]	Loss: 2.816269
1 2.803799629211426
2 2.7651257514953613
3 2.711094379425049
4 2.674734115600586
5 2.599153757095337
6 2.458543062210083
7 2.387197256088257
8 2.2247493267059326
9 2.161306619644165
10 1.9490193128585815
11 1.8676339387893677
12 1.7331511974334717
13 1.9639571905136108
14 1.8582364320755005
15 1.907025933265686
16 1.793813943862915
17 1.846146583557129
18 1.7855781316757202
19 1.872133493423462
20 2.002988338470459
21 1.7759438753128052
22 1.4977489709854126
23 1.835310935974121
24 1.6607835292816162
25 1.8171855211257935
26 1.8684816360473633
27 1.7938765287399292
28 1.4937556982040405
29 1.654280662536621
30 1.6399636268615723
31 1.6656439304351807
32 1.6641792058944702
33 1.6294244527816772
34 1.6433606147766113
35 1.7439838647842407
36 1.5472326278686523
37 1.6367237567901611
38 1.5258233547210693
39 1.5690022706985474
40 1.5816223621368408
41 1.618436336517334
42 1.660224437713623
43 1.536813497543335
44 1.4237838983535767
45 1.4768824577331543
46 1.726176142692566
47 1.607722520828247
48 1.6789636611938477
49 1.6052470207214355
50 1.5223404169082642
51 1.5363835096359253
52 1.5772746801376343
53 1.4888728857040405
54 1.2840462923049927
55 1.5730407238006592
56 1.779089093208313
57 1.5628423690795898
58 1.4690806865692139
59 1.6458548307418823
60 1.6868219375610352
61 1.6042773723602295
62 1.5703009366989136
63 1.56194269657135
64 1.6470943689346313
65 1.6163339614868164
66 1.4760141372680664
67 1.5396373271942139
68 1.5099694728851318
69 1.5717387199401855
70 1.4386138916015625
71 1.639237642288208
72 1.4440088272094727
73 1.4328402280807495
74 1.3925775289535522
75 1.406532883644104
76 1.4072779417037964
77 1.3352938890457153
78 1.4960750341415405
79 1.5217657089233398
80 1.3654862642288208
81 1.4440596103668213
82 1.5383851528167725
83 1.4916616678237915
84 1.249433994293213
85 1.5096685886383057
86 1.630171537399292
87 1.4668785333633423
88 1.3379391431808472
89 1.4398983716964722
90 1.5454797744750977
91 1.622104287147522
92 1.5953642129898071
93 1.4685598611831665
94 1.4620580673217773
95 1.3352727890014648
96 1.4098544120788574
97 1.6331535577774048
98 1.5937122106552124
99 1.409192681312561
100 1.3661457300186157
Train Epoch: 1 [10000/20000 (50%)]	Loss: 1.366146
101 1.5219790935516357
102 1.3829797506332397
103 1.3182377815246582
104 1.4932451248168945
105 1.5712847709655762
106 1.4219552278518677
107 1.4627496004104614
108 1.3799793720245361
109 1.5689151287078857
110 1.4666012525558472
111 1.3666906356811523
112 1.566033959388733
113 1.481468677520752
114 1.2208683490753174
115 1.4205946922302246
116 1.355922818183899
117 1.424483060836792
118 1.269697904586792
119 1.2717089653015137
120 1.4880778789520264
121 1.431898832321167
122 1.355107069015503
123 1.5023895502090454
124 1.2626689672470093
125 1.3509767055511475
126 1.337022066116333
127 1.4358094930648804
128 1.1769334077835083
129 1.4113013744354248
130 1.2739776372909546
131 1.3316973447799683
132 1.2729403972625732
133 1.2966639995574951
134 1.330966591835022
135 1.2127922773361206
136 1.2455275058746338
137 1.144901990890503
138 1.413576602935791
139 1.1326725482940674
140 1.331052541732788
141 1.3744090795516968
142 1.4316303730010986
143 1.323439598083496
144 1.2966419458389282
145 1.3199886083602905
146 1.330070972442627
147 1.3007415533065796
148 1.4442578554153442
149 1.2062032222747803
150 1.2029625177383423
151 1.3347505331039429
152 1.3257020711898804
153 1.250472068786621
154 1.346625804901123
155 1.3826072216033936
156 1.419303297996521
157 1.195691704750061
158 1.4032888412475586
159 1.209905982017517
160 1.3420958518981934
161 1.1524673700332642
162 1.111324429512024
163 1.1454752683639526
164 1.2445101737976074
165 1.1856552362442017
166 1.1245464086532593
167 1.2605206966400146
168 1.2098287343978882
169 1.2015358209609985
170 1.3321298360824585
171 1.2003374099731445
172 1.2337168455123901
173 1.183580756187439
174 1.1520413160324097
175 1.1339102983474731
176 1.3021949529647827
177 1.4295976161956787
178 1.3536550998687744
179 1.3454945087432861
180 1.2221400737762451
181 1.1885303258895874
182 1.2346783876419067
183 1.3202216625213623
184 1.2145755290985107
185 1.183989405632019
186 1.1179592609405518
187 1.2225427627563477
188 1.2462856769561768
189 1.3280469179153442
190 1.2686108350753784
191 1.2651270627975464
192 1.381986379623413
193 1.3712016344070435
194 1.3084303140640259
195 1.30403733253479
196 1.0831443071365356
197 1.2892242670059204
198 1.190812349319458
199 1.3365870714187622
.............
208.94324008747935 43.894752129912376 14.722825322300196
.............
./lab1.pytorch:80: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  output = F.log_softmax(self.linear3(z))
0 1.3373891115188599
Train Epoch: 2 [0/20000 (0%)]	Loss: 1.337389
1 1.3949731588363647
2 1.339293360710144
3 1.2656660079956055
4 1.2345894575119019
5 1.4998472929000854
6 1.0949240922927856
7 1.3357809782028198
8 1.1764720678329468
9 1.3686225414276123
10 1.0775623321533203
11 1.2639716863632202
12 1.1783620119094849
13 1.209667682647705
14 1.2079490423202515
15 1.263526439666748
16 1.267250418663025
17 1.2332063913345337
18 1.3448748588562012
19 1.1918933391571045
20 1.393649697303772
21 1.2764655351638794
22 1.1923882961273193
23 1.3514305353164673
24 1.2890912294387817
25 1.159912347793579
26 1.3391315937042236
27 1.3023468255996704
28 1.159569263458252
29 1.151027798652649
30 1.1632755994796753
31 1.234537959098816
32 1.2000237703323364
33 1.251911997795105
34 1.1911041736602783
35 1.3114715814590454
36 1.1569106578826904
37 1.176461100578308
38 1.1343134641647339
39 1.2974492311477661
40 1.0792959928512573
41 1.2819956541061401
42 1.3957716226577759
43 1.0856952667236328
44 1.082153558731079
45 1.2025738954544067
46 1.3335013389587402
47 1.1925164461135864
48 1.426632046699524
49 1.2851769924163818
50 1.2952239513397217
51 1.208721399307251
52 1.2588753700256348
53 1.1891056299209595
54 1.0063564777374268
55 1.0948740243911743
56 1.3218265771865845
57 1.1891132593154907
58 1.253214955329895
59 1.2834597826004028
60 1.2988308668136597
61 1.1923354864120483
62 1.3045579195022583
63 1.1964532136917114
64 1.1733169555664062
65 1.1869970560073853
66 1.1525779962539673
67 1.406340479850769
68 1.1192710399627686
69 1.2662241458892822
70 1.2420356273651123
71 1.4430820941925049
72 1.206748604774475
73 1.1158461570739746
74 1.2287280559539795
75 1.2428535223007202
76 1.1931467056274414
77 1.0299469232559204
78 1.2528043985366821
79 1.2724275588989258
80 1.307235598564148
81 1.2532567977905273
82 1.2500702142715454
83 1.2151379585266113
84 0.9744711518287659
85 1.298014521598816
86 1.406797170639038
87 1.1847596168518066
88 1.015946865081787
89 1.2176839113235474
90 1.340242862701416
91 1.4253922700881958
92 1.3422367572784424
93 1.2409721612930298
94 1.2980742454528809
95 1.1021738052368164
96 1.169378638267517
97 1.373476266860962
98 1.2000102996826172
99 1.2443499565124512
100 1.1213773488998413
Train Epoch: 2 [10000/20000 (50%)]	Loss: 1.121377
101 1.31640625
102 1.0831588506698608
103 1.1002482175827026
104 1.2543519735336304
105 1.2222466468811035
106 1.1656596660614014
107 1.2347428798675537
108 1.1215879917144775
109 1.349644422531128
110 1.2506088018417358
111 1.1511564254760742
112 1.3167294263839722
113 1.2322059869766235
114 1.1312352418899536
115 1.2898350954055786
116 1.2026278972625732
117 1.2321584224700928
118 1.1791045665740967
119 1.0907176733016968
120 1.298052191734314
121 1.307349681854248
122 1.2340887784957886
123 1.3684419393539429
124 1.1439447402954102
125 1.2060072422027588
126 1.2286313772201538
127 1.309327244758606
128 1.003553867340088
129 1.3008651733398438
130 1.1146942377090454
131 1.1832435131072998
132 1.1448090076446533
133 1.10727858543396
134 1.1123414039611816
135 1.0358312129974365
136 1.1489068269729614
137 0.9878543019294739
138 1.299131155014038
139 1.0522998571395874
140 1.1189682483673096
141 1.224657416343689
142 1.265421986579895
143 1.212032437324524
144 1.1855140924453735
145 1.1731739044189453
146 1.229974627494812
147 1.131134033203125
148 1.298072338104248
149 0.9986770153045654
150 1.1275418996810913
151 1.1843260526657104
152 1.2107683420181274
153 1.1161903142929077
154 1.1835287809371948
155 1.1760120391845703
156 1.3449174165725708
157 1.1026124954223633
158 1.2395703792572021
159 1.111792802810669
160 1.2193520069122314
161 1.032952070236206
162 0.9618775844573975
163 1.0487947463989258
164 1.123498558998108
165 1.0963248014450073
166 1.0143829584121704
167 1.1257892847061157
168 1.0578043460845947
169 1.0162185430526733
170 1.202526569366455
171 1.0864671468734741
172 1.0741126537322998
173 1.0942474603652954
174 1.0156927108764648
175 1.024732232093811
176 1.1687562465667725
177 1.2883349657058716
178 1.2726988792419434
179 1.244868516921997
180 1.106274127960205
181 1.040637493133545
182 1.1433249711990356
183 1.1796696186065674
184 1.0142369270324707
185 1.0626407861709595
186 0.9903762936592102
187 1.1171681880950928
188 1.1191600561141968
189 1.1595263481140137
190 1.121025800704956
191 1.089800477027893
192 1.191557765007019
193 1.292958378791809
194 1.2647420167922974
195 1.0221105813980103
196 0.9657296538352966
197 1.157448410987854
198 1.0444225072860718
199 1.1916632652282715
.............
608.9305833037943 131.86919533461332 42.31769928522408
.............
0 1.1702247858047485
Train Epoch: 3 [0/20000 (0%)]	Loss: 1.170225
1 1.311230182647705
2 1.2651275396347046
3 1.152903437614441
4 1.150246024131775
5 1.3772006034851074
6 0.9208109974861145
7 1.2127584218978882
8 1.0222076177597046
9 1.258587121963501
10 0.9605404138565063
11 1.1235487461090088
12 1.0900542736053467
13 1.0584020614624023
14 1.1440497636795044
15 1.1337745189666748
16 1.1441423892974854
17 1.003329873085022
18 1.2790173292160034
19 1.1046661138534546
20 1.2529789209365845
21 1.1313538551330566
22 1.0180346965789795
23 1.2217414379119873
24 1.1356196403503418
25 1.0583298206329346
26 1.2287644147872925
27 1.1370627880096436
28 1.0934607982635498
29 1.0722007751464844
30 1.047747015953064
31 1.090957522392273
32 1.0718188285827637
33 1.13979971408844
34 1.0844886302947998
35 1.211631417274475
36 0.9892295002937317
37 1.0966113805770874
38 1.0209463834762573
39 1.1754918098449707
40 0.9717159867286682
41 1.1817704439163208
42 1.3425886631011963
43 0.9363335371017456
44 0.9624848365783691
45 1.115385890007019
46 1.2661608457565308
47 1.138034701347351
48 1.3006290197372437
49 1.2167272567749023
50 1.1724750995635986
51 1.101155161857605
52 1.24910569190979
53 1.0408906936645508
54 0.9090156555175781
55 1.0578734874725342
56 1.2026041746139526
57 1.0877583026885986
58 1.1529817581176758
59 1.2195168733596802
60 1.2455312013626099
61 1.142593502998352
62 1.1929912567138672
63 1.062008261680603
64 1.14113450050354
65 1.1626060009002686
66 0.9934287071228027
67 1.2219401597976685
68 1.0776410102844238
69 1.1704761981964111
70 1.08623468875885
71 1.3104037046432495
72 1.1157690286636353
73 1.0726847648620605
74 1.1996363401412964
75 1.098555326461792
76 0.9959114193916321
77 0.9545060992240906
78 1.2124605178833008
79 1.1342742443084717
80 1.102023720741272
81 1.1068286895751953
82 1.1667944192886353
83 1.0165354013442993
84 0.9720660448074341
85 1.166966199874878
86 1.3163337707519531
87 1.0342941284179688
88 0.9071084856987
89 1.1002310514450073
90 1.2799755334854126
91 1.3728382587432861
92 1.2753578424453735
93 1.145403265953064
94 1.1901861429214478
95 1.0252553224563599
96 1.149904727935791
97 1.3439805507659912
98 1.1263971328735352
99 1.1957670450210571
100 1.0053436756134033
Train Epoch: 3 [10000/20000 (50%)]	Loss: 1.005344
101 1.252396821975708
102 1.0874770879745483
103 1.105952262878418
104 1.1619206666946411
105 1.1447393894195557
106 1.128337025642395
107 1.1519659757614136
108 1.00166654586792
109 1.3179429769515991
110 1.1298205852508545
111 1.0432103872299194
112 1.1744089126586914
113 1.2054530382156372
114 0.964183509349823
115 1.1891487836837769
116 1.1905356645584106
117 1.1667022705078125
118 0.9786065816879272
119 1.0167491436004639
120 1.2361822128295898
121 1.2382737398147583
122 1.1052696704864502
123 1.2865839004516602
124 1.0942819118499756
125 1.2057316303253174
126 1.2146124839782715
127 1.242742657661438
128 0.9460313320159912
129 1.2189271450042725
130 1.1034847497940063
131 1.089390754699707
132 1.0950679779052734
133 1.0205094814300537
134 1.056814193725586
135 0.9897596836090088
136 1.1311818361282349
137 0.9059311747550964
138 1.2587459087371826
139 1.1220085620880127
140 1.0615445375442505
141 1.2244545221328735
142 1.2034265995025635
143 1.150006890296936
144 1.194493293762207
145 1.1367558240890503
146 1.1939293146133423
147 1.0356724262237549
148 1.2154659032821655
149 0.9327564239501953
150 1.1172767877578735
151 1.122800350189209
152 1.1510002613067627
153 1.0968753099441528
154 1.1464627981185913
155 1.1157598495483398
156 1.3086377382278442
157 1.0504454374313354
158 1.1497395038604736
159 1.0735023021697998
160 1.173369288444519
161 0.9577912092208862
162 0.9003399610519409
163 0.968207597732544
164 1.0442821979522705
165 1.0654464960098267
166 0.947123110294342
167 1.0556305646896362
168 0.9727963805198669
169 0.9725946187973022
170 1.162919282913208
171 1.0168112516403198
172 1.0131819248199463
173 1.0176299810409546
174 0.9941195845603943
175 0.9670621752738953
176 1.1506798267364502
177 1.208585262298584
178 1.211018443107605
179 1.1652144193649292
180 1.0593739748001099
181 1.0079425573349
182 1.08890962600708
183 1.1209064722061157
184 0.980998694896698
185 1.0232502222061157
186 0.932761549949646
187 1.0692569017410278
188 1.059624195098877
189 1.1299837827682495
190 1.0683512687683105
191 1.0296725034713745
192 1.1266047954559326
193 1.2420706748962402
194 1.2158604860305786
195 0.9581732153892517
196 0.9229739904403687
197 1.0774190425872803
198 1.0088896751403809
199 1.1541560888290405
.............
1439.1522754151374 308.53838608786464 101.58046479709446
.............
0 1.1138944625854492
Train Epoch: 4 [0/20000 (0%)]	Loss: 1.113894
1 1.281204342842102
2 1.2122578620910645
3 1.12894868850708
4 1.0847771167755127
5 1.3289837837219238
6 0.893943190574646
7 1.167689323425293
8 0.9801737070083618
9 1.2111561298370361
10 0.9179213643074036
11 1.0625165700912476
12 1.044732689857483
13 1.0083802938461304
14 1.1332764625549316
15 1.093355417251587
16 1.0790750980377197
17 0.9439465403556824
18 1.2702617645263672
19 1.0518125295639038
20 1.1983147859573364
21 1.08585786819458
22 0.9637012481689453
23 1.1743454933166504
24 1.0970776081085205
25 1.010495662689209
26 1.2018420696258545
27 1.080319881439209
28 1.095717430114746
29 1.0640974044799805
30 1.0188571214675903
31 1.098564624786377
32 1.0302650928497314
33 1.1148778200149536
34 1.0612130165100098
35 1.1782429218292236
36 1.0187208652496338
37 1.0919384956359863
38 1.0056051015853882
39 1.1519131660461426
40 0.9575808048248291
41 1.147215485572815
42 1.3065330982208252
43 0.9065163135528564
44 0.9555630683898926
45 1.0927393436431885
46 1.2278766632080078
47 1.1047042608261108
48 1.2763985395431519
49 1.1374355554580688
50 1.1429516077041626
51 1.0716484785079956
52 1.180524230003357
53 1.0188398361206055
54 0.9056715369224548
55 1.022264003753662
56 1.143523931503296
57 1.0509381294250488
58 1.1247990131378174
59 1.1630414724349976
60 1.1715259552001953
61 1.1174135208129883
62 1.1571853160858154
63 1.006829857826233
64 1.0836565494537354
65 1.0907251834869385
66 0.9599750638008118
67 1.203926682472229
68 1.02837336063385
69 1.1194045543670654
70 1.0331594944000244
71 1.285080909729004
72 1.1048238277435303
73 1.0548052787780762
74 1.156875729560852
75 1.0810348987579346
76 0.9831246733665466
77 0.948258638381958
78 1.1978759765625
79 1.1012555360794067
80 1.0601202249526978
81 1.097313642501831
82 1.1466742753982544
83 0.9851597547531128
84 0.9534628987312317
85 1.1421606540679932
86 1.280683159828186
87 0.99965500831604
88 0.9000388383865356
89 1.0746662616729736
90 1.2640118598937988
91 1.3567405939102173
92 1.271512746810913
93 1.1339627504348755
94 1.165102481842041
95 0.9876569509506226
96 1.1340196132659912
97 1.2831836938858032
98 1.0949031114578247
99 1.1593683958053589
100 0.9701764583587646
Train Epoch: 4 [10000/20000 (50%)]	Loss: 0.970176
101 1.2194559574127197
102 1.068179965019226
103 1.0952479839324951
104 1.1287832260131836
105 1.1141592264175415
106 1.0950424671173096
107 1.1243950128555298
108 0.993557333946228
109 1.2945785522460938
110 1.1017831563949585
111 1.0278288125991821
112 1.1343876123428345
113 1.186816692352295
114 0.9544765949249268
115 1.1494169235229492
116 1.150230884552002
117 1.1328215599060059
118 0.9832394123077393
119 0.9789115190505981
120 1.196683406829834
121 1.2375831604003906
122 1.056031346321106
123 1.241713523864746
124 1.0343559980392456
125 1.1827021837234497
126 1.1996580362319946
127 1.209560751914978
128 0.9420864582061768
129 1.1541435718536377
130 1.1001365184783936
131 1.0383458137512207
132 1.018127202987671
133 0.9756186604499817
134 1.0182712078094482
135 0.9772869348526001
136 1.1273317337036133
137 0.8737741112709045
138 1.23212468624115
139 1.0861893892288208
140 1.0296982526779175
141 1.2338707447052002
142 1.1728688478469849
143 1.113508701324463
144 1.1722908020019531
145 1.121059536933899
146 1.184448480606079
147 0.9988824725151062
148 1.1901086568832397
149 0.9033437371253967
150 1.1054967641830444
151 1.136673092842102
152 1.1325536966323853
153 1.0739374160766602
154 1.1111540794372559
155 1.0824058055877686
156 1.290695309638977
157 1.048272728919983
158 1.130722165107727
159 1.0872176885604858
160 1.1718530654907227
161 0.9490041136741638
162 0.9059156775474548
163 0.9944871664047241
164 1.0308501720428467
165 1.0414824485778809
166 0.9400542378425598
167 1.0325689315795898
168 0.9614129662513733
169 0.9628828167915344
170 1.1523957252502441
171 0.9965619444847107
172 0.9920278787612915
173 0.9849267601966858
174 0.9803930521011353
175 0.9536249041557312
176 1.1414202451705933
177 1.190110683441162
178 1.1962003707885742
179 1.1495999097824097
180 1.0377402305603027
181 0.9912837147712708
182 1.0678739547729492
183 1.0904501676559448
184 0.9677155017852783
185 1.0121873617172241
186 0.9125980138778687
187 1.0475146770477295
188 1.0351321697235107
189 1.1079473495483398
190 1.0452324151992798
191 1.0010390281677246
192 1.0859700441360474
193 1.1973294019699097
194 1.1730377674102783
195 0.9254498481750488
196 0.9052407741546631
197 1.04483962059021
198 0.9814856052398682
199 1.1249412298202515
.............
3094.3208324406296 663.51070859842 220.00402719154954
.............
0 1.082162857055664
Train Epoch: 5 [0/20000 (0%)]	Loss: 1.082163
1 1.2701046466827393
2 1.1869571208953857
3 1.0998262166976929
4 1.0544652938842773
5 1.2894178628921509
6 0.8789218068122864
7 1.1354265213012695
8 0.9622576832771301
9 1.1793456077575684
10 0.9011508822441101
11 1.0323138236999512
12 1.0286412239074707
13 0.9911540746688843
14 1.117795705795288
15 1.0663795471191406
16 1.0419679880142212
17 0.9129453301429749
18 1.2634795904159546
19 1.015356183052063
20 1.1781715154647827
21 1.0566140413284302
22 0.925869345664978
23 1.1427266597747803
24 1.0787354707717896
25 0.978126049041748
26 1.175649881362915
27 1.0401692390441895
28 1.0549322366714478
29 1.0395941734313965
30 0.9675115346908569
31 1.0306181907653809
32 0.9970874190330505
33 1.0639859437942505
34 1.0195207595825195
35 1.1613017320632935
36 0.9613685011863708
37 1.060691475868225
38 0.981669008731842
39 1.1788458824157715
40 0.9307698607444763
41 1.0813432931900024
42 1.2682510614395142
43 0.8887059092521667
44 0.9144975543022156
45 1.0687896013259888
46 1.2485148906707764
47 1.0486338138580322
48 1.2688534259796143
49 1.1115201711654663
50 1.1728190183639526
51 1.080521583557129
52 1.1083792448043823
53 1.0136892795562744
54 0.8998185992240906
55 0.9987131357192993
56 1.1254783868789673
57 1.0446711778640747
58 1.1207072734832764
59 1.1504594087600708
60 1.1462764739990234
61 1.1103336811065674
62 1.1547654867172241
63 0.9700308442115784
64 1.043327808380127
65 1.0569337606430054
66 0.9364778995513916
67 1.1672699451446533
68 1.0173259973526
69 1.0876961946487427
70 0.9826565384864807
71 1.2315826416015625
72 1.0742740631103516
73 1.0158615112304688
74 1.1351127624511719
75 1.039920687675476
76 0.9667920470237732
77 0.920570969581604
78 1.155494213104248
79 1.0602883100509644
80 1.0377216339111328
81 1.0592429637908936
82 1.122106671333313
83 0.9606382250785828
84 0.891813337802887
85 1.1091749668121338
86 1.2159370183944702
87 0.9586837887763977
88 0.8818994164466858
89 1.0436220169067383
90 1.2300336360931396
91 1.32794189453125
92 1.2558106184005737
93 1.0919132232666016
94 1.131273627281189
95 0.941433846950531
96 1.0811984539031982
97 1.1958644390106201
98 1.0677640438079834
99 1.1087881326675415
100 0.9264929294586182
Train Epoch: 5 [10000/20000 (50%)]	Loss: 0.926493
101 1.1843647956848145
102 1.025130033493042
103 1.0397799015045166
104 1.1075352430343628
105 1.09281587600708
106 1.0571085214614868
107 1.1019665002822876
108 0.9796834588050842
109 1.2536611557006836
110 1.0664165019989014
111 1.011551022529602
112 1.069620966911316
113 1.1754944324493408
114 0.9264054894447327
115 1.1228355169296265
116 1.1134415864944458
117 1.0787394046783447
118 0.9552444219589233
119 0.9485111236572266
120 1.1243385076522827
121 1.2345292568206787
122 1.0139273405075073
123 1.130225658416748
124 1.041029930114746
125 1.158527135848999
126 1.157236099243164
127 1.1605132818222046
128 0.9561072587966919
129 1.075742244720459
130 1.0581892728805542
131 1.0278326272964478
132 0.9517925381660461
133 0.9304575324058533
134 0.9924828410148621
135 0.9605993032455444
136 1.0954492092132568
137 0.8495562076568604
138 1.1884311437606812
139 0.998026430606842
140 0.9759771823883057
141 1.205798625946045
142 1.1381146907806396
143 1.0636327266693115
144 1.101582646369934
145 1.077499270439148
146 1.1711901426315308
147 0.9666056632995605
148 1.1671431064605713
149 0.8692986369132996
150 1.024309754371643
151 1.1011230945587158
152 1.0789927244186401
153 1.0501800775527954
154 1.074408769607544
155 1.0189049243927002
156 1.2603758573532104
157 1.0295512676239014
158 1.0560380220413208
159 1.0477858781814575
160 1.1369870901107788
161 0.9209332466125488
162 0.8867495656013489
163 1.0145756006240845
164 1.0113376379013062
165 1.005108118057251
166 0.9520386457443237
167 1.0063027143478394
168 0.922219455242157
169 0.9400634169578552
170 1.1119303703308105
171 0.9709790945053101
172 0.9812692999839783
173 0.9289366006851196
174 0.9232683777809143
175 0.9171008467674255
176 1.1179296970367432
177 1.1682113409042358
178 1.1715086698532104
179 1.0952508449554443
180 1.0249927043914795
181 0.9534178972244263
182 1.0570406913757324
183 1.053550362586975
184 0.9697355628013611
185 0.9849678874015808
186 0.8883724808692932
187 1.0057793855667114
188 1.0026377439498901
189 1.0935803651809692
190 1.0097668170928955
191 0.9760263562202454
192 1.0378284454345703
193 1.1673457622528076
194 1.1501504182815552
195 0.8943576216697693
196 0.8784406781196594
197 0.9965144991874695
198 0.9502618908882141
199 1.0846084356307983
.............
6404.830120358616 1370.451218990609 454.46769084222615
.............
9 6404.830120358616 1370.451218990609 454.46769084222615
.............
