0 2.8771700859069824
Train Epoch: 1 [0/20000 (0%)]	Loss: 2.877170
1 2.842848777770996
2 2.789520263671875
3 2.723353385925293
4 2.672966241836548
5 2.592716932296753
6 2.4453632831573486
7 2.3913750648498535
8 2.2305850982666016
9 2.144196033477783
10 1.96614408493042
11 1.8662240505218506
12 1.769100546836853
13 1.9856845140457153
14 1.8805639743804932
15 1.922135591506958
16 1.7724169492721558
17 1.837949275970459
18 1.775200605392456
19 1.858630657196045
20 2.0021514892578125
21 1.7864999771118164
22 1.502649188041687
23 1.8463035821914673
24 1.6615694761276245
25 1.809992790222168
26 1.8653221130371094
27 1.7769463062286377
28 1.494582176208496
29 1.6660199165344238
30 1.6483317613601685
31 1.660828709602356
32 1.6671977043151855
33 1.6260048151016235
34 1.6452637910842896
35 1.7440781593322754
36 1.542189359664917
37 1.633705735206604
38 1.526648998260498
39 1.5686378479003906
40 1.5886542797088623
41 1.6164193153381348
42 1.6562849283218384
43 1.533935546875
44 1.4262455701828003
45 1.489335298538208
46 1.731203556060791
47 1.6015663146972656
48 1.6750668287277222
49 1.6015108823776245
50 1.5174131393432617
51 1.529909610748291
52 1.5768253803253174
53 1.4799884557724
54 1.2940582036972046
55 1.5714956521987915
56 1.7626575231552124
57 1.5629478693008423
58 1.4697991609573364
59 1.6363836526870728
60 1.6804181337356567
61 1.6002415418624878
62 1.564138650894165
63 1.5653969049453735
64 1.6431454420089722
65 1.6032660007476807
66 1.4596847295761108
67 1.5365469455718994
68 1.5102026462554932
69 1.5826090574264526
70 1.43149733543396
71 1.6284916400909424
72 1.4262346029281616
73 1.4276214838027954
74 1.4052517414093018
75 1.4140957593917847
76 1.4052449464797974
77 1.3291330337524414
78 1.4779024124145508
79 1.5140408277511597
80 1.3662508726119995
81 1.4343523979187012
82 1.53047776222229
83 1.4695185422897339
84 1.2468775510787964
85 1.4932388067245483
86 1.6232900619506836
87 1.4531244039535522
88 1.31882905960083
89 1.4169312715530396
90 1.5338116884231567
91 1.61952543258667
92 1.586266040802002
93 1.45668625831604
94 1.4530019760131836
95 1.3227791786193848
96 1.3988032341003418
97 1.6219364404678345
98 1.578668236732483
99 1.4022204875946045
100 1.3550010919570923
Train Epoch: 1 [10000/20000 (50%)]	Loss: 1.355001
101 1.5069690942764282
102 1.3651723861694336
103 1.308622121810913
104 1.4766850471496582
105 1.545891523361206
106 1.3943907022476196
107 1.4635157585144043
108 1.3772004842758179
109 1.5542428493499756
110 1.4545937776565552
111 1.3465094566345215
112 1.5531598329544067
113 1.4808683395385742
114 1.1984061002731323
115 1.3969231843948364
116 1.3522446155548096
117 1.4075692892074585
118 1.258858323097229
119 1.2539879083633423
120 1.4685784578323364
121 1.4074571132659912
122 1.3400027751922607
123 1.4806877374649048
124 1.244380235671997
125 1.3316879272460938
126 1.3234134912490845
127 1.4151525497436523
128 1.1449041366577148
129 1.412299633026123
130 1.2554495334625244
131 1.3079296350479126
132 1.2835824489593506
133 1.2881903648376465
134 1.3083508014678955
135 1.2092379331588745
136 1.2380293607711792
137 1.133018136024475
138 1.4101678133010864
139 1.1205769777297974
140 1.3076781034469604
141 1.360024094581604
142 1.4070916175842285
143 1.3255195617675781
144 1.2917615175247192
145 1.3126931190490723
146 1.323777198791504
147 1.2870898246765137
148 1.4320158958435059
149 1.1886200904846191
150 1.1954067945480347
151 1.3243904113769531
152 1.3164198398590088
153 1.2398701906204224
154 1.333511233329773
155 1.371635913848877
156 1.416304588317871
157 1.1878777742385864
158 1.3959040641784668
159 1.1989620923995972
160 1.3351712226867676
161 1.1397342681884766
162 1.1061886548995972
163 1.1326656341552734
164 1.2316251993179321
165 1.1800159215927124
166 1.1092355251312256
167 1.2469967603683472
168 1.1998194456100464
169 1.1771641969680786
170 1.330889105796814
171 1.194846749305725
172 1.2239552736282349
173 1.1730422973632812
174 1.1382752656936646
175 1.128312587738037
176 1.3017892837524414
177 1.4215302467346191
178 1.3460617065429688
179 1.3369848728179932
180 1.221052885055542
181 1.188748836517334
182 1.2314637899398804
183 1.3195443153381348
184 1.2211649417877197
185 1.1799583435058594
186 1.1107292175292969
187 1.2100719213485718
188 1.2440931797027588
189 1.3174941539764404
190 1.2665257453918457
191 1.2628589868545532
192 1.3791725635528564
193 1.3582664728164673
194 1.300901174545288
195 1.2996846437454224
196 1.0735456943511963
197 1.2726359367370605
198 1.188390851020813
199 1.3354345560073853
./lab1.pytorch:82: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  output = F.log_softmax(self.linear3(z))
0 1.334018588066101
Train Epoch: 2 [0/20000 (0%)]	Loss: 1.334019
1 1.3997507095336914
2 1.3306881189346313
3 1.244081735610962
4 1.229688286781311
5 1.4815958738327026
6 1.0896564722061157
7 1.332998514175415
8 1.1796541213989258
9 1.3456337451934814
10 1.0717660188674927
11 1.2486737966537476
12 1.1680546998977661
13 1.1949272155761719
14 1.2069847583770752
15 1.2626744508743286
16 1.2618141174316406
17 1.2444018125534058
18 1.338307499885559
19 1.1892457008361816
20 1.3622114658355713
21 1.2742294073104858
22 1.1800388097763062
23 1.3540478944778442
24 1.3068846464157104
25 1.158231258392334
26 1.324744462966919
27 1.281682014465332
28 1.1564124822616577
29 1.1388400793075562
30 1.1674054861068726
31 1.2440725564956665
32 1.2009692192077637
33 1.2447034120559692
34 1.186479926109314
35 1.3081790208816528
36 1.1401002407073975
37 1.167028546333313
38 1.1396162509918213
39 1.302390694618225
40 1.0771896839141846
41 1.276116967201233
42 1.3814821243286133
43 1.0843318700790405
44 1.0823684930801392
45 1.1994423866271973
46 1.3338350057601929
47 1.1996327638626099
48 1.4340488910675049
49 1.2882623672485352
50 1.3055768013000488
51 1.1994848251342773
52 1.260683298110962
53 1.1937907934188843
54 1.0242842435836792
55 1.0887597799301147
56 1.2980800867080688
57 1.1805977821350098
58 1.2439448833465576
59 1.2761982679367065
60 1.29439377784729
61 1.1926649808883667
62 1.3029705286026
63 1.1926453113555908
64 1.1812195777893066
65 1.1700623035430908
66 1.1484729051589966
67 1.4013062715530396
68 1.1141231060028076
69 1.2543567419052124
70 1.2270084619522095
71 1.4320265054702759
72 1.201347827911377
73 1.109196424484253
74 1.2312934398651123
75 1.2440407276153564
76 1.1817011833190918
77 1.01973295211792
78 1.2520593404769897
79 1.281904697418213
80 1.298370361328125
81 1.2337334156036377
82 1.2596572637557983
83 1.2480300664901733
84 0.9766970276832581
85 1.2709330320358276
86 1.3970152139663696
87 1.1931161880493164
88 1.026273488998413
89 1.2013466358184814
90 1.3329870700836182
91 1.4249258041381836
92 1.3459243774414062
93 1.2407630681991577
94 1.2922724485397339
95 1.1139419078826904
96 1.172531247138977
97 1.3778725862503052
98 1.2051920890808105
99 1.240307092666626
100 1.1207668781280518
Train Epoch: 2 [10000/20000 (50%)]	Loss: 1.120767
101 1.3164114952087402
102 1.0843513011932373
103 1.1011149883270264
104 1.2617135047912598
105 1.2291563749313354
106 1.1747369766235352
107 1.2346326112747192
108 1.1205395460128784
109 1.3590714931488037
110 1.2531237602233887
111 1.1495451927185059
112 1.3206508159637451
113 1.234578251838684
114 1.103525161743164
115 1.2813830375671387
116 1.2119537591934204
117 1.234649658203125
118 1.1780433654785156
119 1.0915776491165161
120 1.2932547330856323
121 1.304845929145813
122 1.2271723747253418
123 1.3701863288879395
124 1.1219371557235718
125 1.219878911972046
126 1.2357919216156006
127 1.3046983480453491
128 1.0012747049331665
129 1.2810146808624268
130 1.1142151355743408
131 1.1925641298294067
132 1.134463906288147
133 1.0879775285720825
134 1.116564154624939
135 1.038068175315857
136 1.1543071269989014
137 0.9908265471458435
138 1.298872947692871
139 1.029916524887085
140 1.1256712675094604
141 1.2333040237426758
142 1.270031452178955
143 1.212347388267517
144 1.1852750778198242
145 1.1717064380645752
146 1.2409034967422485
147 1.1322013139724731
148 1.303462266921997
149 1.021907925605774
150 1.0863699913024902
151 1.178310751914978
152 1.201550006866455
153 1.1221548318862915
154 1.1709517240524292
155 1.1780999898910522
156 1.3485424518585205
157 1.102735996246338
158 1.2366840839385986
159 1.0995312929153442
160 1.2250176668167114
161 1.0181409120559692
162 0.9620917439460754
163 1.0338897705078125
164 1.13164484500885
165 1.097318172454834
166 0.9966057538986206
167 1.119930624961853
168 1.0611233711242676
169 1.0141199827194214
170 1.2220274209976196
171 1.0978392362594604
172 1.0808626413345337
173 1.0845974683761597
174 1.0220664739608765
175 1.042783260345459
176 1.1844172477722168
177 1.280358910560608
178 1.2729026079177856
179 1.252648115158081
180 1.1164538860321045
181 1.0600311756134033
182 1.1455886363983154
183 1.1918303966522217
184 1.0254334211349487
185 1.0621519088745117
186 0.9974811673164368
187 1.1283066272735596
188 1.132777214050293
189 1.1897556781768799
190 1.137058973312378
191 1.093531608581543
192 1.1986396312713623
193 1.2997918128967285
194 1.281928539276123
195 1.0405488014221191
196 0.9627443552017212
197 1.1633025407791138
198 1.0544496774673462
199 1.1997591257095337
0 1.183028221130371
Train Epoch: 3 [0/20000 (0%)]	Loss: 1.183028
1 1.3145685195922852
2 1.259526014328003
3 1.1445701122283936
4 1.1575262546539307
5 1.3796368837356567
6 0.9214450716972351
7 1.209449052810669
8 1.0281310081481934
9 1.2591264247894287
10 0.9641598463058472
11 1.130878210067749
12 1.110075831413269
13 1.0691877603530884
14 1.1467430591583252
15 1.1385911703109741
16 1.152828335762024
17 1.012607455253601
18 1.280617356300354
19 1.1079243421554565
20 1.2562408447265625
21 1.139021635055542
22 1.026800274848938
23 1.2322745323181152
24 1.1462986469268799
25 1.063591480255127
26 1.220448613166809
27 1.148274302482605
28 1.086266279220581
29 1.0726436376571655
30 1.0619020462036133
31 1.0930155515670776
32 1.0684417486190796
33 1.1407891511917114
34 1.0990886688232422
35 1.2195366621017456
36 0.9960348606109619
37 1.0901135206222534
38 1.0325617790222168
39 1.1854993104934692
40 0.9937893748283386
41 1.1816903352737427
42 1.3305412530899048
43 0.9589536190032959
44 0.9687398672103882
45 1.1210075616836548
46 1.2756431102752686
47 1.1318968534469604
48 1.3159966468811035
49 1.235385537147522
50 1.2081669569015503
51 1.1178083419799805
52 1.2357133626937866
53 1.065931797027588
54 0.9080127477645874
55 1.0603214502334595
56 1.2217011451721191
57 1.1073845624923706
58 1.161557674407959
59 1.2205098867416382
60 1.267008900642395
61 1.1561613082885742
62 1.1960316896438599
63 1.063172698020935
64 1.1552830934524536
65 1.1505138874053955
66 1.0020502805709839
67 1.2122950553894043
68 1.0820101499557495
69 1.15372633934021
70 1.0893011093139648
71 1.304349422454834
72 1.1168322563171387
73 1.0677058696746826
74 1.199581265449524
75 1.0904029607772827
76 1.0043361186981201
77 0.9532493352890015
78 1.2026549577713013
79 1.1369911432266235
80 1.1128555536270142
81 1.1082777976989746
82 1.1864606142044067
83 1.0220948457717896
84 0.967724621295929
85 1.178248643875122
86 1.29328191280365
87 1.0401192903518677
88 0.920359194278717
89 1.0950047969818115
90 1.270565390586853
91 1.3795608282089233
92 1.2759697437286377
93 1.1407657861709595
94 1.2032004594802856
95 1.0200014114379883
96 1.1313998699188232
97 1.348331093788147
98 1.1358531713485718
99 1.1953758001327515
100 1.0122312307357788
Train Epoch: 3 [10000/20000 (50%)]	Loss: 1.012231
101 1.2622250318527222
102 1.0977307558059692
103 1.094160556793213
104 1.1708877086639404
105 1.1616233587265015
106 1.144242286682129
107 1.1578103303909302
108 1.0032330751419067
109 1.3106186389923096
110 1.1355030536651611
111 1.049077033996582
112 1.175674557685852
113 1.211776852607727
114 0.9569393992424011
115 1.1973153352737427
116 1.214497685432434
117 1.1776105165481567
118 0.9762914776802063
119 1.0166794061660767
120 1.230557918548584
121 1.253660798072815
122 1.1103813648223877
123 1.2911791801452637
124 1.0827540159225464
125 1.2027366161346436
126 1.2206975221633911
127 1.23149836063385
128 0.952460527420044
129 1.2250345945358276
130 1.110766053199768
131 1.084234595298767
132 1.0982460975646973
133 1.0335131883621216
134 1.0450111627578735
135 0.9885616898536682
136 1.1254936456680298
137 0.9079164266586304
138 1.267593502998352
139 1.1260348558425903
140 1.0626791715621948
141 1.2244991064071655
142 1.2079253196716309
143 1.142493486404419
144 1.1851845979690552
145 1.1323221921920776
146 1.200610637664795
147 1.0467612743377686
148 1.2100334167480469
149 0.9405760169029236
150 1.10453462600708
151 1.123378038406372
152 1.1565335988998413
153 1.1004672050476074
154 1.1521817445755005
155 1.125798225402832
156 1.3171833753585815
157 1.0577088594436646
158 1.1531891822814941
159 1.073155403137207
160 1.1715799570083618
161 0.9537169933319092
162 0.9021527171134949
163 0.9658041596412659
164 1.055151104927063
165 1.06881582736969
166 0.940992534160614
167 1.0611382722854614
168 0.9787433743476868
169 0.9689226746559143
170 1.170346736907959
171 1.021115779876709
172 1.0086315870285034
173 1.0228854417800903
174 0.9937832355499268
175 0.9749175310134888
176 1.1475051641464233
177 1.2136330604553223
178 1.226059913635254
179 1.169287919998169
180 1.0633080005645752
181 1.0175423622131348
182 1.0965629816055298
183 1.1236834526062012
184 0.9829243421554565
185 1.0212053060531616
186 0.936972439289093
187 1.0747188329696655
188 1.0659687519073486
189 1.134964108467102
190 1.0719585418701172
191 1.034792423248291
192 1.1362239122390747
193 1.2420496940612793
194 1.2196435928344727
195 0.9656260013580322
196 0.9238733649253845
197 1.0842392444610596
198 1.0170608758926392
199 1.1646119356155396
0 1.117746114730835
Train Epoch: 4 [0/20000 (0%)]	Loss: 1.117746
1 1.2836241722106934
2 1.213280439376831
3 1.1318299770355225
4 1.0954395532608032
5 1.333221435546875
6 0.8979504108428955
7 1.1634236574172974
8 0.9776491522789001
9 1.2089905738830566
10 0.9186506867408752
11 1.065057635307312
12 1.054506778717041
13 1.009814977645874
14 1.1369894742965698
15 1.1059184074401855
16 1.086248755455017
17 0.9423500895500183
18 1.2729930877685547
19 1.0573064088821411
20 1.199169635772705
21 1.090295672416687
22 0.9670804738998413
23 1.1836674213409424
24 1.1055876016616821
25 1.0133222341537476
26 1.1970875263214111
27 1.0911109447479248
28 1.0884132385253906
29 1.0635404586791992
30 1.0318069458007812
31 1.1086938381195068
32 1.023850679397583
33 1.1160849332809448
34 1.0754063129425049
35 1.1836435794830322
36 1.0259904861450195
37 1.0905379056930542
38 1.0086811780929565
39 1.144559621810913
40 0.9662435054779053
41 1.1401596069335938
42 1.3009414672851562
43 0.913825273513794
44 0.9527128338813782
45 1.0973410606384277
46 1.2147449254989624
47 1.1062275171279907
48 1.2894200086593628
49 1.1407526731491089
50 1.1457452774047852
51 1.0749932527542114
52 1.1778044700622559
53 1.0207908153533936
54 0.9109379053115845
55 1.0264220237731934
56 1.1451524496078491
57 1.0525269508361816
58 1.1159552335739136
59 1.1705882549285889
60 1.1743690967559814
61 1.1191052198410034
62 1.1521846055984497
63 1.0069342851638794
64 1.0729025602340698
65 1.0856300592422485
66 0.9671701788902283
67 1.2038263082504272
68 1.0172053575515747
69 1.1211400032043457
70 1.02861750125885
71 1.300727128982544
72 1.1029497385025024
73 1.0634045600891113
74 1.158898115158081
75 1.1002519130706787
76 0.972688615322113
77 0.9487518072128296
78 1.1973247528076172
79 1.108256459236145
80 1.0708131790161133
81 1.0909210443496704
82 1.1411397457122803
83 0.9814395904541016
84 0.9411621689796448
85 1.140748143196106
86 1.2837496995925903
87 0.9964308142662048
88 0.8943661451339722
89 1.074761152267456
90 1.2496122121810913
91 1.3558471202850342
92 1.2692539691925049
93 1.1260840892791748
94 1.1432135105133057
95 1.0010063648223877
96 1.1308728456497192
97 1.3028672933578491
98 1.0950243473052979
99 1.1660467386245728
100 0.9700572490692139
Train Epoch: 4 [10000/20000 (50%)]	Loss: 0.970057
101 1.2145451307296753
102 1.063339352607727
103 1.0938615798950195
104 1.132480502128601
105 1.1196459531784058
106 1.0971550941467285
107 1.1246644258499146
108 1.0033392906188965
109 1.3039742708206177
110 1.111312747001648
111 1.0343871116638184
112 1.143479585647583
113 1.2168887853622437
114 0.9613872766494751
115 1.1584290266036987
116 1.1660610437393188
117 1.1398186683654785
118 0.9778491854667664
119 0.990953266620636
120 1.2080093622207642
121 1.2343498468399048
122 1.0645331144332886
123 1.2546489238739014
124 1.0401333570480347
125 1.194830298423767
126 1.2058994770050049
127 1.220852255821228
128 0.9397470951080322
129 1.1664764881134033
130 1.0968317985534668
131 1.0423576831817627
132 1.0400581359863281
133 0.9838624596595764
134 1.0285844802856445
135 0.9753490686416626
136 1.124884009361267
137 0.8788869380950928
138 1.2450181245803833
139 1.114420771598816
140 1.0374157428741455
141 1.236697793006897
142 1.1823488473892212
143 1.1168699264526367
144 1.1796165704727173
145 1.1304835081100464
146 1.1943591833114624
147 1.00887930393219
148 1.192273736000061
149 0.9126309752464294
150 1.0989627838134766
151 1.1503057479858398
152 1.1447339057922363
153 1.0766159296035767
154 1.1200093030929565
155 1.1034796237945557
156 1.308000087738037
157 1.0624017715454102
158 1.1385626792907715
159 1.104569911956787
160 1.1820573806762695
161 0.9494237303733826
162 0.9119691252708435
163 0.9946790337562561
164 1.039170265197754
165 1.0475541353225708
166 0.946174681186676
167 1.0432277917861938
168 0.9742294549942017
169 0.9604827761650085
170 1.1541643142700195
171 0.9984758496284485
172 0.9901764392852783
173 0.9978075623512268
174 0.9993225336074829
175 0.9597525596618652
176 1.1493433713912964
177 1.1973638534545898
178 1.2008256912231445
179 1.1624209880828857
180 1.0440698862075806
181 0.9979768991470337
182 1.0710371732711792
183 1.0955928564071655
184 0.9672198295593262
185 1.0188182592391968
186 0.9166748523712158
187 1.0616488456726074
188 1.0474927425384521
189 1.1082768440246582
190 1.0518659353256226
191 1.011510968208313
192 1.1005403995513916
193 1.2035956382751465
194 1.1864252090454102
195 0.9345299005508423
196 0.9098390340805054
197 1.047096610069275
198 0.9857374429702759
199 1.1366010904312134
0 1.086052417755127
Train Epoch: 5 [0/20000 (0%)]	Loss: 1.086052
1 1.274369478225708
2 1.189900517463684
3 1.110677719116211
4 1.0540410280227661
5 1.299750804901123
6 0.8818444609642029
7 1.1453986167907715
8 0.9655244946479797
9 1.1871354579925537
10 0.9166077375411987
11 1.039229154586792
12 1.0414544343948364
13 1.0056747198104858
14 1.1261998414993286
15 1.0715423822402954
16 1.054894208908081
17 0.9112319946289062
18 1.2652984857559204
19 1.0224875211715698
20 1.1800377368927002
21 1.0628042221069336
22 0.931551456451416
23 1.1505286693572998
24 1.0900532007217407
25 0.9837791919708252
26 1.1872433423995972
27 1.0463690757751465
28 1.0552676916122437
29 1.0443912744522095
30 0.9723519086837769
31 1.0436792373657227
32 0.997870683670044
33 1.0751605033874512
34 1.0333912372589111
35 1.1684828996658325
36 0.968407154083252
37 1.0625312328338623
38 0.9913036823272705
39 1.1688405275344849
40 0.9529697299003601
41 1.0919997692108154
42 1.2761870622634888
43 0.9021514058113098
44 0.9285297393798828
45 1.0822384357452393
46 1.232825756072998
47 1.0508211851119995
48 1.283619999885559
49 1.116126537322998
50 1.1775927543640137
51 1.0821869373321533
52 1.1178375482559204
53 1.0222185850143433
54 0.9039717316627502
55 1.001265048980713
56 1.1210933923721313
57 1.0453912019729614
58 1.1193451881408691
59 1.1470719575881958
60 1.1514300107955933
61 1.116103172302246
62 1.1415762901306152
63 0.9685377478599548
64 1.0495169162750244
65 1.0521585941314697
66 0.9396018385887146
67 1.169789433479309
68 1.0138064622879028
69 1.0781104564666748
70 0.9878047108650208
71 1.2413290739059448
72 1.0893429517745972
73 1.0299302339553833
74 1.1365540027618408
75 1.0508522987365723
76 0.9696134328842163
77 0.9329403042793274
78 1.1666793823242188
79 1.0773155689239502
80 1.0446748733520508
81 1.0651843547821045
82 1.13279128074646
83 0.9657192230224609
84 0.9031157493591309
85 1.1161874532699585
86 1.2222760915756226
87 0.9696686267852783
88 0.8905925750732422
89 1.0401002168655396
90 1.234857201576233
91 1.333848237991333
92 1.2556240558624268
93 1.0990115404129028
94 1.1384339332580566
95 0.9587540626525879
96 1.0857521295547485
97 1.2184205055236816
98 1.0812289714813232
99 1.1241438388824463
100 0.9337671399116516
Train Epoch: 5 [10000/20000 (50%)]	Loss: 0.933767
101 1.1828614473342896
102 1.0215086936950684
103 1.043384313583374
104 1.1091476678848267
105 1.0882197618484497
106 1.0567574501037598
107 1.1054521799087524
108 0.9832978248596191
109 1.2625445127487183
110 1.088084101676941
111 1.0219112634658813
112 1.0926860570907593
113 1.1933857202529907
114 0.9438490271568298
115 1.1325985193252563
116 1.1315288543701172
117 1.1058354377746582
118 0.9684388637542725
119 0.9556952714920044
120 1.1447780132293701
121 1.2561718225479126
122 1.0391556024551392
123 1.1724498271942139
124 1.0226079225540161
125 1.1817630529403687
126 1.1815972328186035
127 1.1666067838668823
128 0.9573679566383362
129 1.1062912940979004
130 1.080735683441162
131 1.0232648849487305
132 0.9658697247505188
133 0.939931333065033
134 0.9931014180183411
135 0.9528260827064514
136 1.0833632946014404
137 0.8504883050918579
138 1.2029975652694702
139 1.029176950454712
140 0.9954829216003418
141 1.2154197692871094
142 1.149882197380066
143 1.075930118560791
144 1.1222535371780396
145 1.0844522714614868
146 1.1712414026260376
147 0.9832890033721924
148 1.1676172018051147
149 0.8772926330566406
150 1.0469368696212769
151 1.1216968297958374
152 1.0934277772903442
153 1.061712622642517
154 1.093700647354126
155 1.0397639274597168
156 1.2762023210525513
157 1.0487174987792969
158 1.081030011177063
159 1.0642099380493164
160 1.1543686389923096
161 0.9341869354248047
162 0.904937207698822
163 1.0209169387817383
164 1.032890796661377
165 1.0197303295135498
166 0.9362196922302246
167 1.0255399942398071
168 0.9503989219665527
169 0.9526324272155762
170 1.1388616561889648
171 0.989855945110321
172 0.9875368475914001
173 0.9631348252296448
174 0.9691867232322693
175 0.9313891530036926
176 1.1313860416412354
177 1.1790517568588257
178 1.180603265762329
179 1.133222222328186
180 1.0292936563491821
181 0.9738675951957703
182 1.0636569261550903
183 1.066225528717041
184 0.9557167887687683
185 0.9977399706840515
186 0.892168402671814
187 1.0320351123809814
188 1.0271921157836914
189 1.079098105430603
190 1.014965534210205
191 0.9857640266418457
192 1.0556331872940063
193 1.162400722503662
194 1.1418993473052979
195 0.9054207801818848
196 0.8855226039886475
197 1.0001758337020874
198 0.9516822695732117
199 1.0926562547683716
2 3391.858502730727 1446.7693802788854 1.7620623111724854e-05
.............
